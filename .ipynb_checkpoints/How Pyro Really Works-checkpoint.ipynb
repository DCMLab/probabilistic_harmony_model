{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How Pyro Really Works\n",
    "\n",
    "## or How to Write Yourself a Probabilistic Programming Framwork\n",
    "## or Please Try This at Home\n",
    "\n",
    "Ever wondered how pyro (or probabilistic programming in general) really works? How does it do variational inference, and what is that in the first place? It's conceptually simpler than one might think, because it follows from the combination of a handful of rather simple ideas. In this tutorial we will look at each of them in turn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Joint, Marginal, and Conditional Distributions\n",
    "\n",
    "#### Summary:\n",
    "\n",
    "- If we have a *joint distribution* ($p(A,B)$),\n",
    "  we can express *marginal* ($p(A)$) and *conditional distributions* $p(A \\mid B)$ based on the joint distribution\n",
    "- Conversely, joint distributions can always be *factorized* into a product of conditional and marginal distributions\n",
    "  $$ p(A,B) = p(A \\mid B) p(B) $$\n",
    "- Sampling the variables in some order gives rise to a factorization\n",
    "  $$ p(x_1, \\ldots, x_n) = \\prod_i p(x_i \\mid x_1, \\ldots x_{i-1}) $$\n",
    "  and describes a *generative process*.\n",
    "\n",
    "### Basics\n",
    "\n",
    "Probability distributions may be defined on several random variables (RVs), e.g. $A$, $B$, and $C$. The distribution over all variables $p(A,B,C)$ is called the *joint distribution*, which is normalized such that the sum over all possible RV assignments is 1. (In the continuous case, we integrate instead of summing.)\n",
    "\n",
    "The *marginal distribution* of a subset of the RVs is obtained from the joint distribution by summing (or integrating) over all remaining variables. for example\n",
    "$$ p(A) = \\sum_B \\sum_C p(A,B,C) $$\n",
    "and\n",
    "$$ p(A,B) = \\sum_C p(A,B,C) $$\n",
    "\n",
    "A *conditional distribution* is the distribution of some of the RVs given that other RVs are known to have a certain value, e.g. $p(A,B \\mid C=c)$.\n",
    "If the value of the known RV is arbitrary, we write $p(A,B \\mid C)$.\n",
    "If we are only interested in the distribution of some of the unknown RVs, we can again marginalize out the remaining unknown RVs, e.g.\n",
    "$$ p(A \\mid C) = \\sum_B p(A, B | C) $$\n",
    "\n",
    "We can obtain the conditional distribution from the joint distribution by fixing the value of the known RVs ($p(A,B,C=c)$).\n",
    "Since we now only look at a subset of the RV assignment (e.g. those in which $C=c$), we have to renormalize by the probability to have one of these assignments $p(C=c)$:\n",
    "$$ p(A,B \\mid C=c) = \\dfrac{p(A,B,C=c)}{p(C=c)}$$\n",
    "or more generally\n",
    "$$ p(A,B \\mid C) = \\dfrac{p(A,B,C)}{p(C)} $$\n",
    "\n",
    "### Factorizing a Joint Distribution\n",
    "\n",
    "From the above section it follows that every joint distribution can be factorized into simpler conditional and marginal distributions.\n",
    "For example, we can turn the previous equation around and obtain\n",
    "$$ p(A,B,C) = p(A,B \\mid C) p(C) $$\n",
    "\n",
    "Since $p(A,B \\mid C)$ can be understood as another joint distribution (of $A$ and $B$, given $C$), it can be factorized again (given $C$!), e.g.:\n",
    "$$ p(A,B \\mid C) = p(A \\mid B,C) p(B \\mid C) $$\n",
    "\n",
    "and consequently\n",
    "$$ p(A,B,C) = p(A,B \\mid C) p(C) = p(A \\mid B,C) p(B \\mid C) p(C). $$\n",
    "\n",
    "Note that the order in which we factor out variables doesn't matter, so the following is equivalent:\n",
    "$$ p(A,B,C) = p(B,C \\mid A) p(A) = p(B \\mid C,A) p(C \\mid A) p(A). $$\n",
    "\n",
    "We can understand any factorization as an ordering of the RVs when sampling from the joint distribution.\n",
    "Instead of sampling all of them together, we sample each RV from its conditional distribution, starting with the one that is sampled from its unconditional marginal distribution.\n",
    "For example, in the first factorization above ($p(A \\mid B,C) p(B \\mid C) p(C)$, we first sample $C$ from $p(C)$, which doesn't depend on any of the other RVs.\n",
    "Then, knowing the value $c$ of $C$, we can sample $B$ from $p(B \\mid C=c)$, and finally (knowing $B=b$ and $C=c$) we can sample $A$ from $p(A \\mid B=b, C=c)$.\n",
    "Thus we have turned the joint distribution $p(A,B,C)$ into a *generative process* that produces each RV in turn.\n",
    "\n",
    "### Exercises\n",
    "\n",
    "1. Given the joint distribution $p(A,B,C,D)$, what is the marginal distribution $p(A,C)$?\n",
    "1. Given the same joint distribution $p(A,B,C,D)$, what is the conditional distribution $p(A,B | C)$?\n",
    "   Express it only using the joint distribution.\n",
    "1. Let $p(X,Y,Z) = p(Z \\mid X,Y) p(X) p(Y)$. What is $p(X \\mid Y$? What is $p(Y \\mid Z, X)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Bayesian Inference\n",
    "\n",
    "#### Summary\n",
    "\n",
    "- Bayesian models are defined by a *joint distribution* $p(X,Z)$\n",
    "  over observed ($X$) and unobserved variables ($Z$).\n",
    "- Bayesian inference is computing the *posterior distribution* $p(Z \\mid X)$.\n",
    "- Sometimes, the joint distribution is given as factorized into a *likelihood* $p(X \\mid Z)$ and a *prior* $p(Z)$.\n",
    "\n",
    "### Bayesian Models\n",
    "\n",
    "Bayesian inference builds on the \"bayesian\" interpretation of probabilities as talking about the plausibility of statements.\n",
    "BI starts from the assumption that we can define a joint *plausibility distribution* over observed ($X$) and unobserved variables ($Z$): $p(X,Z)$, which assings a plausibility $p(X=x, Z=z)$ to any particular instantiation of $X$ and $Z$.\n",
    "Doing *inference* means to asses the plausibility of latent variable assignments, given that the observed variables take some (observed) value: $p(Z \\mid X=x)$.\n",
    "\n",
    "#### Example\n",
    "\n",
    "While the above may sound very abstract, a common situation in which it is useful is when we have a probabilistic model (i.e. a probability distribution) of some data $d$, i.e. a distribution so that we can interpret the data $d$ as sampled from a random variable $D$.\n",
    "Our distribution over $D$ has some parameters $\\theta$, so we can write it as $p_\\theta(D)$.\n",
    "If we change $\\theta$, we change the distribution.\n",
    "\n",
    "Now we want a good value for $\\theta$.\n",
    "Since the distribution is suppose to \"model\" the data, we want $\\theta$ to be chosen such that $D=d$ has a very high probability under $p_\\theta$.\n",
    "In other words, we want to maximize the function $\\theta \\to p_\\theta(D=d)$.\n",
    "This function is called the *likelihood function* and the optimal value for $\\theta$ is called the *maximum likelihood estimate* (MLE).\n",
    "\n",
    "While we know that the MLE is the \"best\" value of $\\theta$ given $d$, we don't really know how it compares to other possible values, i.e. *how* good it really is.\n",
    "In other words, we want to know how *plausible* it is that some value of $\\theta$ is the \"true\" $\\theta$ that was used to generate the data.\n",
    "We can quantify the plausibility of different $\\theta$ values as a plausibility distribution $p(\\theta \\mid D=d)$.\n",
    "Note the similarity to the general description of bayesian inference above, where we look for $p(Z \\mid X=x)$.\n",
    "Just like in the case above we can derive $p(Z \\mid X=x)$ from $p(X,Z)$, we can now derive $p(\\theta \\mid D=d)$ from the joint distribution $p(D, \\theta)$.\n",
    "This joint distribution describes the plausibility of certain values of $\\theta$ and $D$ occurring together.\n",
    "\n",
    "---\n",
    "\n",
    "#### Definition\n",
    "\n",
    "A **bayesian model** is defined by a joint distribution $p(X,Z)$ over *unobserved (/hidden/latent) variables* $Z$ (e.g. model parameters) and *observed variables* $X$.\n",
    "\n",
    "**Bayesian inference** is about infering a plausibility distribution over the $Z$ given observed values for the $X$: $p(Z \\mid X=x)$.\n",
    "This distribution is called the *posterior distribution*, because it expresses our beliefs about the latent variables *after* knowing the values of the observed variable.\n",
    "\n",
    "---\n",
    "\n",
    "### Inference in Bayesian Models\n",
    "\n",
    "How can we compute $p(Z \\mid X=x)$?\n",
    "We know from the definition of conditional probability that\n",
    "$$ p(Z \\mid X=x) = \\dfrac{p(X,Z)}{p(X)}, $$\n",
    "so we can in principle derive the posterior distribution from the joint distribution.\n",
    "But where does the join distribution come from?\n",
    "\n",
    "Remember that, in many cases, we know (or assume to know) the likelihood, i.e. $p(X \\mid Z)$.\n",
    "We also know that the likelihood relates to the joint distribution by\n",
    "$$ p(X,Z) = p(X \\mid Z) p(Z), $$\n",
    "i.e. the joint distribution *factorizes* into the likelihood and the *prior distribution*,\n",
    "the marginal distribution of the hidden variables.\n",
    "\n",
    "What is the prior distribution?\n",
    "We know that it is the marginal distribution of $Z$, so we can interpret it as describing the plausibility of values for $Z$ given that $X$ could take *any* values (we even sum/integrate over all values for $X$).\n",
    "In other words, $p(Z)$ expresses our beliefs about $Z$ irrespective of $X$, i.e. *before* observing $X$.\n",
    "If we can somehow encode our prior beliefs about $Z$ as a distribution, we can combine it the likelihood to obtain a joint distribution.\n",
    "\n",
    "Combining the likelihood and the prior, we can make our formula for the posterior more precise:\n",
    "$$ p(Z \\mid X=x) = \\dfrac{p(X \\mid Z) p(Z)}{p(X=x)}, $$\n",
    "which is known as *Bayes' theorem*.\n",
    "The marginal probability of the data $p(X=x)$ is called *evidence* and serves to normalize the posterior when expressed in terms of prior and likelihood.\n",
    "While it is often impossible to compute the evidence (because it requires summing/integrating over all $Z$),\n",
    "it is constant for a given dataset ($X=x$), so we might want to write the posterior as\n",
    "$$ p(Z \\mid X=x) \\propto p(X \\mid Z) p(Z). $$\n",
    "\n",
    "#### Side Remark\n",
    "\n",
    "Bayesian inference is often introduced in terms of Bayes' theorem, i.e. distinguishing likelihood and prior,\n",
    "this is just special case.\n",
    "Generally, what is required is only a joint distribution.\n",
    "Since we often know the likelihood and can construct reasonable priors, they just provide a convenient factorization of the joint distribution.\n",
    "\n",
    "### Exercises\n",
    "\n",
    "1. Show that Bayes' theorem follows directly from the possibility to factorize a joint distribution in different ways.\n",
    "2. You have a dataset of measurements $d = [3, 4.5, 5, 3.5]$.\n",
    "   You think that each data point is drawn independently from the same normal distribution with mean $\\mu$ and standard deviation $\\sigma = 1$,\n",
    "   i.e. $p(d) = \\prod_i p(d_i)$ where $d_i \\sim \\text{Normal}(\\mu, 1)$.\n",
    "   \n",
    "   What is the MLE for $\\mu$?\n",
    "   Derive a general formula as well as the MLE for above dataset.\n",
    "   Remember that the density function for the normal distribution is\n",
    "   $$ f(x) = \\dfrac{1}{\\sigma \\sqrt{\\tau}} e^{-\\dfrac{1}{2}\\left(\\dfrac{x-\\mu}{\\sigma}\\right)^2}. $$\n",
    "   Use the fact that maximizing $l(x)$ is the same as maximizing $\\log(l(x))$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Probabilistic Programming 1: Writing Probabilistic Programs\n",
    "\n",
    "#### Summary\n",
    "\n",
    "- Any Python program that samples values defines a probability distribution.\n",
    "- We can obtain a sample from the distribution by running the program and tracking each randomly chosen value\n",
    "  using a `sample` function, which gives the value a name.\n",
    "- Each \"random value\" can be understood as an assignment of a random variable.\n",
    "\n",
    "### Wrting Probabilistic Programs\n",
    "\n",
    "The idea of probabilistic programming is to define a joint probability distribution over several RVs as a generative process, i.e. a programm that draws samples from the joint distribution.\n",
    "The advantage of this is that it's a lot easier to do and a lot more readble than defining a closed formula for the whole joint distribution.\n",
    "The disadvantage is that it it's much more difficult to perform analytic math on a program.\n",
    "FWIW, a program is something that we can execute but not much more, we can't really look inside.\n",
    "But let's first look at the advantages, we'll deal with the disadvantages later.\n",
    "\n",
    "Let's assume that we want to implement our own little probabilistic programming framework.\n",
    "What do we need?\n",
    "First of all, we need a way to write programs that produce some kind of output.\n",
    "Fortunately, programming languages are already very good at letting you write pograms.\n",
    "For example, we can use Python to write a function that computes and returns some kind of result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_function():\n",
    "    x = 10\n",
    "    y = x*2\n",
    "    return y\n",
    "\n",
    "my_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the above function is a program that computes a deterministic value, a probabilistic program is a mix of deterministic computation and random sampling.\n",
    "For example, the following function flips a coin to determine whether `y` should be `x*2` or `x*3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def my_random_function(p=0.5):\n",
    "    x = 10\n",
    "    heads = random.random() < p\n",
    "    y = x*2 if heads else x*3\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we run this function several times, it will return different results, sometimes 20 and sometimes 30, depending on the result of the coin flip.\n",
    "We can look at the distribution over the result by running the programm several times and collecting the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "results = [my_random_function() for i in range(100)]\n",
    "\n",
    "counts = Counter(results)\n",
    "plt.bar(counts.keys(), counts.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we provide a different coin probability, the result distribution will be different as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = [my_random_function(0.1) for i in range(100)]\n",
    "\n",
    "counts = Counter(results)\n",
    "plt.bar(counts.keys(), counts.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that while the function returns `y`, which is randomly distributed,\n",
    "the actual sampling happens when we flip the coin, so we might want to say that `heads` is the actual random variable an `y` is just a deterministic transformation of it.\n",
    "However, since the only thing we can do with `my_random_function` is to execute it, we can't directly look at the distribution of `heads`.\n",
    "Let's change this by \"recording\" the value of `heads` every time we call `my_random_function`.\n",
    "\n",
    "We write a little helper function called `sample` that use to record the values we sampled for random variables.\n",
    "Just like we can use `print` to print any value as a side effect, we can use `sample` to record a random variable as a side effect.\n",
    "We store the RV values in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rv_dict = dict()\n",
    "\n",
    "def clear_rvs():\n",
    "    global rv_dict\n",
    "    rv_dict = dict()\n",
    "\n",
    "def sample(name, value):\n",
    "    rv_dict[name] = value\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we adapt `my_random_function` to use `sample` to record the value of `heads`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "{'heads': False}\n"
     ]
    }
   ],
   "source": [
    "def my_random_function(p=0.5):\n",
    "    x = 10\n",
    "    heads = sample(\"heads\", random.random() < p)\n",
    "    y = x*2 if heads else x*3\n",
    "    return y\n",
    "\n",
    "clear_rvs()\n",
    "result = my_random_function()\n",
    "print(result)\n",
    "print(rv_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, after running `my_random_function` again, the value of `heads` is recorded in `rv_dict` and the return value of `my_random_function` corresponds to the recorded value of heads.\n",
    "\n",
    "What if we want to record several RVs? We can do that too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({(False, False): 37,\n",
       "         (False, True): 41,\n",
       "         (True, False): 9,\n",
       "         (True, True): 13})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def flip_two_coins(p1=0.5, p2=0.5):\n",
    "    coin1 = sample(\"coin1\", random.random() < p1)\n",
    "    coin2 = sample(\"coin2\", random.random() < p2)\n",
    "\n",
    "results = []\n",
    "for i in range(100):\n",
    "    clear_rvs()              # clear the recorded values\n",
    "    flip_two_coins(0.2, 0.6) # record new values \n",
    "    results.append((rv_dict[\"coin1\"], rv_dict[\"coin2\"]))\n",
    "    \n",
    "counts = Counter(results)\n",
    "counts\n",
    "#plt.bar(counts.keys(), counts.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that creating many samples from this distribution (as we do above) gives us an estimate of how the random variables are distributed.\n",
    "In this case, we get the approximate frequency of every possible variable assignment, which converges to the true probability of every variable assignment when the number of samples goes to infinity.\n",
    "Even in the continuous case we can get an estimate of the shape of the distribution by drawing many samples,\n",
    "but we would have to draw many more samples (depending on the complexity of the shape) and the number of possible configurations grows exponentially with the number of variables, so just sampling is not always a good solution.\n",
    "\n",
    "### Exercises\n",
    "\n",
    "1. Let's go bayesian! Write a probabilistic program that flips a coin with probability $p$,\n",
    "   but first samples the probability $p$ from a uniform distribution $\\text{U}(0,1)$.\n",
    "   Note how this defines a joint distribution over the parameter $p$ and the result of the coin.\n",
    "1. Extend your program to flip not just 1 coin but 100, each with probability $p$.\n",
    "   Make sure that each flipped coin is a recorded as a random variable.\n",
    "   How would you write the probability distribution for the sequence of coin flips mathematically?\n",
    "1. Write a more complex program that simulates how a chord is constructed from a profile.\n",
    "   First, sample the type of the chord $t$ from a categorical distribution over chord types.\n",
    "   Then sample a number of notes $n$ from a poisson distribution (add 1 to the value to avoid 0s).\n",
    "   Finally sample $n$ notes from a multinomial distribution with the weights that correspond to $h$.\n",
    "   The parameters (weights for $h$, rate for $n$ and weights for the notes for each $h$) are given as arguments to the function.\n",
    "1. Extend the previous program to also sample the parameters from a prior distribution.\n",
    "   (Hint: use Dirichlet priors for the weight vectors and a Gamma prior for the rate of the Poisson distribution)\n",
    "1. Extend the previous program to sample a flexible number of chords (provided as an argument)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Probabilistic Programming 2: Evaluating Probabilities\n",
    "\n",
    "#### Summary\n",
    "\n",
    "- We want to be able to evaluate the probability of a given sample from the joint distribution.\n",
    "- We do that by introducing two new things:\n",
    "  - Random values are drawn from `Distribution`s which can\n",
    "    - generate a new random value and\n",
    "    - evaluate the probability of a given value.\n",
    "  - The `sample` function gets an additional interpretation that\n",
    "    - returns the given value of the RV and\n",
    "    - tracks that values local probability under the given distribution.\n",
    "- The joint probability of the sample is the product of all local probabilities.\n",
    "  - The local probabilities are conditional distributions\n",
    "  - The probabilistic program defines a factorization of the joint distribution into local conditional distributions.\n",
    "- Any probabilistic program written using `sample` and `Distributions` can be used to\n",
    "  - draw a sample\n",
    "  - evaluate the probability of a given sample\n",
    "  - despite containing arbitrary Python code with unknown control flow.\n",
    "- Drawing and evaluating samples is sufficient for inference.\n",
    "\n",
    "So far, we have defined a probability distribution implicitly as a program that produces samples from the distribution.\n",
    "We have also seen that by sampling a lot from this distribution, we can estimate it's shape.\n",
    "While this is already useful, it's not quite enough to make serious inference, especially for more complex models.\n",
    "There is one more thing that we need: In addition to sampling from the distribution, we also need to be able to evaluate the probability of a given sample.\n",
    "With these two things, we will be able to do pretty much everything we need for performing bayesian inference.\n",
    "(If it's not clear to you why, don't worry, it will be explained later).\n",
    "\n",
    "In their current form, our probabilistic programs are a bit too implicit to be used for evaluating the probability of a sample.\n",
    "However, we have already introduced a bit of structure by requiring random variables to be registered with the `sample` function.\n",
    "It turns out that if we add a tiny little bit more structure, we can do probability evaluation too,\n",
    "without changing our programs too much.\n",
    "\n",
    "The first thing we need to do is to combine the ability to *sample* a value for a RV with the ability to evaluate its *local probability*.\n",
    "Consider how we sampled the value of our coin in the prevous part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'heads': True}\n"
     ]
    }
   ],
   "source": [
    "def flip_coin(p=0.5):\n",
    "    sample(\"heads\", random.random() < p)\n",
    "\n",
    "clear_rvs()\n",
    "flip_coin()\n",
    "print(rv_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that for the RV \"heads\" we know exactly from which distribution we sample it.\n",
    "In this case, it's taken from a Bernoulli distribution.\n",
    "Since we know how we sample \"heads\", we also know the probability of each possible value of \"heads\":\n",
    "for `True` it's $p$ and for `False` it's $1-p$.\n",
    "\n",
    "Let's make this connection a bit more formal.\n",
    "We have an object (a probability distribution) that can do two things: provide a sample from it and evaluate the probability of a given sample.\n",
    "In python, we can express this idea using a class with two methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abstract base class for distributions\n",
    "class Distribution:\n",
    "    \"Return a sample from the distribution.\"\n",
    "    def sample():\n",
    "        pass\n",
    "    \n",
    "    \"Return the log probability of a given sample from the distribution.\"\n",
    "    def log_p(value):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the second method returns the log probability instead of the probability.\n",
    "The reason for this is that probabilities sometimes get very small and can become 0 due to representation errors.\n",
    "This doesn't happen so easily in log space,\n",
    "and it's trivial to obtain the log probability when the normal probability is known (and vice versa).\n",
    "\n",
    "We can now implement this class for the Bernoulli distribution that formalizes our coin flip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "p(True)  = 0.4\n",
      "p(False) = 0.6\n"
     ]
    }
   ],
   "source": [
    "class Bernoulli(Distribution):\n",
    "    def __init__(self, p):\n",
    "        self.p = p\n",
    "    \n",
    "    def sample(self):\n",
    "        return random.random() < self.p\n",
    "    \n",
    "    def log_p(self, heads):\n",
    "        return np.log(self.p if heads else 1-self.p)\n",
    "\n",
    "coin = Bernoulli(0.4)\n",
    "print(coin.sample())\n",
    "print(\"p(True)  =\", np.exp(coin.log_p(True)))\n",
    "print(\"p(False) =\", np.exp(coin.log_p(False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a way to express primitive distributions that can be used for both sampling and evaluating the log probability, we require our probabilistic programs to use them.\n",
    "Let's change the definition of `sample` to take a distribution object and `.sample()` from it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(name, dist):\n",
    "    value = dist.sample()\n",
    "    rv_dict[name] = value\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we also have to change our program to make use of the `Bernoulli` distribution and the new way `sample` works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'heads': True}\n"
     ]
    }
   ],
   "source": [
    "def flip_coin(p):\n",
    "    sample(\"heads\", Bernoulli(p))\n",
    "\n",
    "clear_rvs()\n",
    "flip_coin(0.4)\n",
    "print(rv_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works like a charm.\n",
    "\n",
    "We still can't make use of the `log_p` method to evaluate the probability of a value for \"heads\".\n",
    "However, since we require using `sample` to track random variables, we already have access to the place where RVs and distributions meet.\n",
    "We could in principle write a different `sample` function that doesn't actually sample and record a fresh value for some RV, but instead looks up the value from a table that we provide beforehand and records it's log probability under the distribution that is provided!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_values = {}\n",
    "recorded_probs = {}\n",
    "\n",
    "def clear_recorded_probs():\n",
    "    global recorded_probs\n",
    "    recorded_probs = {}\n",
    "\n",
    "# our reimplementation of sample that evaluates probabilities\n",
    "def sample(name, dist):\n",
    "    value = known_values[name]\n",
    "    recorded_probs[name] = dist.log_p(value)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we set `known_values` to contain values for all RVs and run our model again, we should now be able to obtain the local probabilities for each RV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(heads = True)  = 0.4\n",
      "p(heads = False) = 0.6\n"
     ]
    }
   ],
   "source": [
    "# run the model for 'heads' = True\n",
    "known_values = {'heads': True}\n",
    "clear_recorded_probs()\n",
    "flip_coin(0.4)\n",
    "print(\"p(heads = True)  =\", np.exp(recorded_probs['heads']))\n",
    "\n",
    "# run the model for 'heads' = False\n",
    "known_values = {'heads': False}\n",
    "clear_recorded_probs()\n",
    "flip_coin(0.4)\n",
    "print(\"p(heads = False) =\", np.exp(recorded_probs['heads']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's still a bit inconvenient that we have to redefine `sample` depending on whether we want to sample or to evaluate.\n",
    "Ideally, we should be able to abstract over the interpretation of `sample`.\n",
    "For example, we can make it look it's functionality up in a variable that we can change to \"sample\" or \"evaluate\" or some other actual interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_function = None\n",
    "\n",
    "def sample(name, dist):\n",
    "    return sample_function(name, dist)\n",
    "\n",
    "# implementation of \"sample\" that samples and records a value (standard interpretation)\n",
    "def sample_sample(name, dist):\n",
    "    value = dist.sample()\n",
    "    rv_dict[name] = value\n",
    "    return value\n",
    "\n",
    "# implementation of \"sample\" that returns the already know value for a RV and records its local probability\n",
    "def sample_eval(name, dist):\n",
    "    value = known_values[name]\n",
    "    recorded_probs[name] = dist.log_p(value)\n",
    "    return value\n",
    "\n",
    "# we set sample_function to be sample_sample by default\n",
    "sample_function = sample_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can freely change the interpretation `sample` to draw samples or evaluate probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'heads': False}\n",
      "{'heads': -0.916290731874155}\n"
     ]
    }
   ],
   "source": [
    "# draw a sample\n",
    "clear_rvs()\n",
    "\n",
    "sample_function = sample_sample\n",
    "flip_coin(0.4)\n",
    "\n",
    "print(rv_dict)\n",
    "\n",
    "# evaluate a sample\n",
    "known_values = {'heads': True}\n",
    "clear_recorded_probs()\n",
    "\n",
    "sample_function = sample_eval\n",
    "flip_coin(0.4)\n",
    "\n",
    "print(recorded_probs) #print the log probs for all RVs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the same for a more complex model.\n",
    "We flip two coins, but the probability of the second depends on the outcome of the first.\n",
    "Fortunately, `sample_eval` returns the observed value for the first coin, the when running the model with observed values, it will choose the correct probability parameters for the second coin, just as if the value of the first coin would have been sampled randomly!\n",
    "\n",
    "We can try this out by first drawing a sample and then evaluating the probability of that sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'coin1': False, 'coin2': False}\n",
      "{'coin1': 0.5, 'coin2': 0.8}\n"
     ]
    }
   ],
   "source": [
    "# our shiny two-coin model\n",
    "def flip_two_coins():\n",
    "    coin1 = sample('coin1', Bernoulli(0.5))\n",
    "    coin2 = sample('coin2', Bernoulli(0.8 if coin1 else 0.2))\n",
    "\n",
    "# draw a sample\n",
    "clear_rvs()\n",
    "sample_function = sample_sample\n",
    "flip_two_coins()\n",
    "print(rv_dict)\n",
    "\n",
    "# evaluate the sample\n",
    "clear_recorded_probs()\n",
    "known_values = rv_dict # take the sample from the previous run\n",
    "sample_function = sample_eval\n",
    "flip_two_coins()\n",
    "print({name: np.exp(prob) for (name,prob) in recorded_probs.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the probability of the second coin is evaluated correctly wrt. the first coin!\n",
    "That's because when the model is run again, it picks the parameters for the second Bernoulli distribution according to the observed value of the first coin.\n",
    "The second `sample` call therefore is given the Bernoulli distribution with the correct parameters and can evaluate the probability of the second coin's value correctly.\n",
    "\n",
    "Congratulations, you have now implemented a probabilistic programming language!\n",
    "We already have everything we need to sample from and evaluate samples under joint distributions that are defined as arbitrary Python programs.\n",
    "As long as the actual random decisions are made using `sample` and from a `Distribution`, the remainder of the model can be arbitrary Python code.\n",
    "In fact, `sample` and `Distribution`s are the only \"language\" constructs we needed to add to ordinary Python for writing models.\n",
    "All the inference stuff can now be done outside of the models in a generic, model-independent way.\n",
    "\n",
    "\"But wait,\" you might object \"we only computed the 'local probability' of each RV, not the joint probability of the whole assignment! And what is that 'local probability' even supposed to mean?\"\n",
    "It turns out that the local probablities are all we need to compute the joint probability of the assignment.\n",
    "All we have to do is to multiply them (or rather sum the log probabilities and take the exponential)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(coin1 = False , coin2 = False ) =  0.4\n"
     ]
    }
   ],
   "source": [
    "def joint_log_p(rv_log_probs):\n",
    "    return sum(rv_log_probs.values())\n",
    "\n",
    "prob = np.exp(joint_log_p(recorded_probs))\n",
    "print(\"p(coin1 =\", rv_dict['coin1'], \", coin2 =\", rv_dict['coin2'], \") = \", prob) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why does this work?\n",
    "\n",
    "Remember that any joint probability distribution can be turned into a generative process by factorizing it into a sequence of conditional distributions.\n",
    "For example $p(A,B,C)$ can be factorized into $p(A) p(B \\mid A) p(C \\mid A, B)$,\n",
    "which corresponds to a process that first samples $A$ then, $B$ given $A$, and finally $C$ given $A$ and $B$.\n",
    "\n",
    "A probabilistic program is exactly such a factorization, corresponding to the order in which the RVs are sampled in the program.\n",
    "For example, the model `flip_two_coins` first samples `coin1` from $p(\\text{coin1})$ and then `coin2` from $p(\\text{coin2} \\mid \\text{coin1})$,\n",
    "and we know that $p(\\text{coin1}) p(\\text{coin2} \\mid \\text{coin1}) = p(\\text{coin1}, \\text{coin2})$.\n",
    "Now we can see that the \"local probability\" of a RV actually is the *conditional probability* of that RV given all the RVs that were sampled before!\n",
    "\n",
    "Note that a variable after another variable does not need to depend on that earlier variable.\n",
    "For example, we might sample $A$, $B$, and $C$ in that order, but maybe $B$ is sampled from a distribution that is fixed and independent of $A$, so the distribution factorizes into $p(A) p(B) p(C \\mid A,B)$.\n",
    "However, if $A$ and $B$ are independent, then it holds that $p(B \\mid A) = p(B)$,\n",
    "so $p(A) p(B) p(C \\mid A,B) = p(A) p(B \\mid A) p(C \\mid A,B)$!\n",
    "\n",
    "Finally, the order need not be defined beforehand. Consider, for example the following model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': True, 'B': False, 'C': False}\n"
     ]
    }
   ],
   "source": [
    "def weird_model():\n",
    "    a = sample(\"A\", Bernoulli(0.5))\n",
    "    if a:\n",
    "        b = sample(\"B\", Bernoulli(0.3))\n",
    "        c = sample(\"C\", Bernoulli(0.2 if b else 0.6))\n",
    "    else:\n",
    "        c = sample(\"C\", Bernoulli(0.4))\n",
    "        b = sample(\"B\", Bernoulli(0.1 if c else 0.2))\n",
    "\n",
    "clear_rvs()\n",
    "sample_function = sample_sample\n",
    "weird_model()\n",
    "print(rv_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this model, the factorization depends on $A$.\n",
    "If $A$ is `True`, then $B$ is sampled first and $C$ depends on $B$\n",
    "$$ p(A = \\text{True},B,C) = p(A = \\text{True}) p(B \\mid A = \\text{True}) p(C \\mid A = \\text{True}, B) $$\n",
    "\n",
    "If $A$ is `False`, it's the other way round.\n",
    "$$ p(A = \\text{False},B,C) = p(A = \\text{False}) p(C \\mid A = \\text{False}) p(B \\mid C, A = \\text{False}) $$\n",
    "\n",
    "Since we only want to evaluate complete assignments, it's sufficient to know that the \"local\" probabilities are *a* factorization of the joint distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "tbd."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Inference\n",
    "\n",
    "#### Summary\n",
    "\n",
    "- we want to know $p(Z \\mid X=x)$ \n",
    "  - can't be derived analytically\n",
    "  - we could sample, but it's expensive\n",
    "- approximation\n",
    "  - choose a variational familiy (\"guide\" in pyro) $q_\\phi(Z)$\n",
    "  - try to optimize $\\phi$ to minimize $\\text{KL}(q(Z) \\parallel p(Z \\mid X=x))$\n",
    "  - we can't compute the KL directly, but we can optimize it via the equivalent \"ELBO\".\n",
    "  - the mean-field family is often a good choice for the guide.\n",
    "\n",
    "In the previous sections we have learned how we can write probabilistic programs in a way that allows us to (a) sample from the joint distribution and (b) evaluate the probability of a sample (i.e. a full variable assingment).\n",
    "But how do we obtain the posterior distribution when conditioning on observations of some RVs, i.e. $p(Z \\mid X=x)$?\n",
    "\n",
    "### Sampling\n",
    "\n",
    "First let's note that while we can use our probabilistic program to sample from the joint distribution, we can't use it directly to sample from the posterior distribution.\n",
    "A naive attempt at doing so could be to add a new implementation of `sample`\n",
    "- samples unobserved RVs normally, and\n",
    "- returns the observed value for observed variables.\n",
    "\n",
    "However, this would not sample from the conditional distribution.\n",
    "To see why, consider the following program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_coins():\n",
    "    c1 = sample(\"c1\", Bernoulli(0.5))\n",
    "    c2 = sample(\"c2\", Bernoulli(0.9 if c1 else 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we observe that $c_2$ is heads, what do you think $c_1$ was?\n",
    "It's more likely that $c_1$ was heads (`True`) than tails (`False`) since heads for $c_1$ makes heads for $c_2$ much more likely.\n",
    "We can even quantify the distribution $p(c_1 \\mid c_2 = \\text{heads})$ exactly using Bayes' formula:\n",
    "$$\n",
    "  p(c_1 \\mid c_2 = \\text{heads}) = \\dfrac{p(c_2 = \\text{heads} \\mid c_1) p(c_1)}{p(c_2 = \\text{heads})}\\\\\n",
    "  p(c_1 = \\text{heads} \\mid c_2 = \\text{heads}) = \\dfrac{p(c_2 = \\text{heads} \\mid c_1 = \\text{heads}) p(c_1 = \\text{heads})}{p(c_2 = \\text{heads})} = \\dfrac{0.9 \\cdot 0.5}{0.5 \\cdot 0.9 + 0.5 \\cdot 0.1} = 0.9\\\\\n",
    "  p(c_1 = \\text{tails} \\mid c_2 = \\text{heads}) = \\dfrac{p(c_2 = \\text{heads} \\mid c_1 = \\text{tails}) p(c_1 = \\text{tails})}{p(c_2 = \\text{heads})} = \\dfrac{0.1 \\cdot 0.5}{0.5 \\cdot 0.9 + 0.5 \\cdot 0.1} = 0.1\\\\\n",
    "$$\n",
    "But imagine we would sample from `simple_coins` as described above, simply fixing \"c2\" to be heads.\n",
    "We would still sample $c_1$ from $\\text{Bernoulli}(0.5)$, although $c_1 \\mid (c_2 = \\text{heads}) \\sim \\text{Bernoulli}(0.9)$!\n",
    "Generally, there is a difference between \"intervention\" (simply fixing the values of the observed RVs without touching the others) and \"conditioning\" (changing the distribution of the unobserved variables to reflect the conditional distribution).\n",
    "\n",
    "However, there are other methods by which we can use a program like `simple_coins` to sample from the posterior distribution.\n",
    "The most simple and universal one is called *rejection sampling*.\n",
    "It draws normal samples from joint distribution, but since we are only interested in the cases where some \"condition\" holds (e.g. that $c_2 = \\text{heads}$), it \"rejects\" all samples where the condition is not true.\n",
    "This is as simple to implement as it sounds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({True: 40, False: 8})\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "sample_function = sample_sample\n",
    "n = 100\n",
    "samples_c1 = []\n",
    "\n",
    "# draw n samples\n",
    "for _ in range(n):\n",
    "    clear_rvs()\n",
    "    # draw the sample\n",
    "    simple_coins()\n",
    "    # check if the condition is satisfied\n",
    "    if rv_dict[\"c2\"] == True:\n",
    "        # record the value of c1\n",
    "        samples_c1.append(rv_dict[\"c1\"])\n",
    "\n",
    "# count and plot the outcome\n",
    "counts_c1 = Counter(samples_c1)\n",
    "plt.bar([str(k) for k in counts_c1.keys()], counts_c1.values())\n",
    "plt.show()\n",
    "print(counts_c1)\n",
    "print(len(samples_c1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the samples of $c_1$ are distributed roughly according to the posterior distribution (with $p=0.9$ rather than $0.5$).\n",
    "But you probably have also noticed, that we have to throw away roughly half of our samples\n",
    "since the condition is only satisfied with probability 0.5!\n",
    "As you can imagine, if the probability of the condition becomes less likely, rejection sampling becomes rather inefficient.\n",
    "For example, our condition is normally the observation of a large dataset,\n",
    "and the probability of the condition is the probability to generate exactly that dataset from the model by chance!\n",
    "\n",
    "There are smarter ways of sampling from the conditional distribution such as [Metropolis-Hastings](https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm) sampling,\n",
    "which requires the ability to evaluate the probability of a sample (which we know how to do).\n",
    "However, sampling methods have some general disadvantages,\n",
    "for example that they don't provide us with a closed formula for (an approximation of) the posterior,\n",
    "unless combined with other methods such as kernel-density estimation.\n",
    "Therefore, we will now focus on a different method called \"variational inference\".\n",
    "It is, however, important to note that our way of defining probabilistic programs using `sample` is in principle sufficient to use advanced sampling algorithms on arbitrary models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational Inference\n",
    "\n",
    "(This section is basically a short summary of [Blei et al., 2017](https://www.tandfonline.com/doi/full/10.1080/01621459.2017.1285773))\n",
    "\n",
    "Remember that our goal is to determine the posterior distribution $p(Z \\mid X=x)$.\n",
    "While the posterior distribution can in principle be obtained via Bayes' formula,\n",
    "it requires to compute the normalization factor $p(X=x)$ (the \"evidence\"),\n",
    "which doesn't always have a closed form.\n",
    "\n",
    "Variational inference is based on the idea that instead of computing the posterior $p(Z \\mid X=x)$ directly, we *approximate* it by a different distribution $q(Z)$.\n",
    "We can do this by choosing a *familiy* of distributions $q_\\phi(Z)$,\n",
    "for which we try to find the optimal parameters $\\phi$ so that $q_\\phi(Z)$ is as similar to $p(Z \\mid X=x)$ as possible.\n",
    "What does \"similar\" mean?\n",
    "Since we talk about the similarity of distributions, a useful measure is the Kullback-Leibler divergence,\n",
    "which measures the \"expected\" difference of one distribution from another distribution:\n",
    "\n",
    "$$\n",
    "    \\text{KL}(p_1 \\parallel p_2)\n",
    "    = \\sum_x p_1(X=x) \\log \\left( \\dfrac{p_1(X=x)}{p_2(X=x)} \\right)\n",
    "    = \\mathbf{E}_{p_1}[\\log p_1(X)] - \\mathbf{E}_{p_1}[\\log p_2(X)].\n",
    "$$\n",
    "\n",
    "Note that the KL divergence is not symmetric, since the expected value is taken with respect to $p_1$!\n",
    "\n",
    "If we apply the KL divergence to the variational distribution $q_\\phi(Z)$ and the posterior $p(Z \\mid X=x)$,\n",
    "we get\n",
    "\n",
    "$$\n",
    "    \\text{KL}(q_\\phi(Z) \\parallel p(Z \\mid X=x)) = \\mathbf{E}_{q_\\phi}[\\log q_\\phi(Z)] - \\mathbf{E}_{q_\\phi}[\\log p(Z \\mid X=x)]\n",
    "$$\n",
    "\n",
    "Finding the best $\\phi$ now amounts to minimizing the KL divergence as stated above, so we have an objective function for optimizing $\\phi$!\n",
    "The problem is that we can't evaluate this objective function since we can't evaluate $p(Z \\mid X=x)$;\n",
    "our probabilistic programs only allow us to evaluate probabilities wrt. the joint distribution $p(X,Z)$.\n",
    "However, remember that we can rewrite $p(Z \\mid X=x)$ as\n",
    "$\\dfrac{p(X=x, Z)}{p(X=x)}.$\n",
    "The numerator is given by the joint distribution, so we can evaluate it.\n",
    "The denominator is the \"evidence\"; we can't evaluate it (which creates the whole problem in the first place), but we know that, for a given $x$, $p(X=x)$ is constant, and constants are irrelevant to an optimiziation objective.\n",
    "\n",
    "Let's apply this insight to our objective function:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\text{KL}(q_\\phi(Z) \\parallel p(Z \\mid X=x))\n",
    "    &= \\mathbf{E}_{q_\\phi}[\\log q_\\phi(Z)] - \\mathbf{E}_{q_\\phi}[\\log p(X=x, Z) - \\log p(X=x)]\\\\\n",
    "    &= \\mathbf{E}_{q_\\phi}[\\log q_\\phi(Z)] - \\mathbf{E}_{q_\\phi}[\\log p(X=x,Z)] + \\log p(X=x).\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Since the term $\\log p(X=x)$ is constant, we can ignore it for optimization and define the \"ELBO\" as:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\text{ELBO}(q_\\phi) &= \\log p(X=x) - \\text{KL}(q(Z) \\parallel p(Z \\mid X=x))\\\\\n",
    "    &= \\mathbf{E}_{q_\\phi}[\\log p(X=x,Z)] - \\mathbf{E}_{q_\\phi}[\\log q_\\phi(Z)].\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Note the change of sign: Instead of minimizing the KL divergence, we maximize the the ELBO, but the optimal parameters $\\phi$ are the same for both.\n",
    "ELBO stands for \"evidence lower bound\", because it is a lower bound to the log evidence $\\log p(X=x)$,\n",
    "as we can see from the equation above.\n",
    "If $q_\\phi$ and the posterior distribution are the same,\n",
    "then the KL divergence is 0 and  $\\text{ELBO}(q_\\phi) = \\log p(X=x)$.\n",
    "If $q_\\phi$ is an imperfect approximation of the posterior,\n",
    "then the KL divergence is positive and $\\text{ELBO}(q_\\phi) < \\log p(X=x)$,\n",
    "so generally\n",
    "\n",
    "$$\n",
    "    \\text{ELBO}(q_\\phi) \\leq \\log p(X=x).\n",
    "$$\n",
    "\n",
    "Note that the ELBO requires us to compute expected values wrt. $q_\\phi$.\n",
    "While this may be intractable (because we have to sum/integrate over $Z$),\n",
    "we can estimate these expectation by drawing samples of $Z$ from $q_\\phi$.\n",
    "Fortunately, we already know how express distributions that we can sample from,\n",
    "namely as probabilistic programs.\n",
    "We don't know yet how to optimize them, but that's the topic of the next section.\n",
    "\n",
    "The question remains how we choose the family $q_\\phi$.\n",
    "It needs to be flexible enough to allow for good approximations of the posterior while being simple enough to be optimized efficiently.\n",
    "A common strategy is to use a *mean-field* family, which treats each latent variable as independent.\n",
    "This family is easy to optimize and can capture any marginal distribution of individual variables,\n",
    "but it can't express correlations between latent variables.\n",
    "However, since we are often interested in the marginal posteriors of individual latent variables (e.g. to asses the certainty about an inferred parameter of our model), the mean-field family is very useful.\n",
    "\n",
    "In general, we can write the mean-field family as\n",
    "\n",
    "$$\n",
    "    q(Z) = \\prod_i q_i(Z_i),\n",
    "$$\n",
    "\n",
    "where each $q_i$ comes with its own parameters.\n",
    "We then choose a plausible $q_i$ for each latent variable $Z_i$.\n",
    "If you don't know anything else, the family of the variables conjugate prior is a good choice,\n",
    "but in principle any distribution with the same support as $Z_i$ works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples\n",
    "\n",
    "Let's look at some concrete examples now.\n",
    "First, we go back to our problem above, where we tried to infer the outcome of the first coin flip from the second.\n",
    "As a reminder, here is our model again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_coins():\n",
    "    c1 = sample(\"c1\", Bernoulli(0.5))\n",
    "    c2 = sample(\"c2\", Bernoulli(0.9 if c1 else 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how do we choose our variational family $q_\\phi$?\n",
    "First of all, we know that it only concerns one variable, namely $c_1$, which is a binary variable.\n",
    "We also know that every possible distribution over a single binary varible is a Bernoulli distribution.\n",
    "Therefore, we know that the posterior $p(c_1 \\mid c_2)$ must also be a Bernoulli distribution,\n",
    "so the Bernoulli family is our best choice for $q_\\phi$, with $\\phi$ being the Bernoulli parameter.\n",
    "\n",
    "Since $q_\\phi$ is a family of distributions, we can now express it as a probabilistic program that takes some parameters ($\\phi$).\n",
    "Everytime we call this program with certain parameters, it describes a distribution, a member of the family $q_\\phi$.\n",
    "In pyro, the variational family is called *guide*, so we are going to follow this convention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_coins_guide(phi):\n",
    "    sample(\"c1\", Bernoulli(phi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how we `sample` $c_1$ just as we do in `simple_coins`.\n",
    "That's because we want to express that the RVs of the guide are the same as the unobserved variables of the model.\n",
    "The goal is now to find a `phi` that optimizes then ELBO between `simple_coins_guide` and the posterior of `simple_coins`.\n",
    "How we can do that will be the topic of the next section.\n",
    "\n",
    "Now let's look at another, slightly more complex example.\n",
    "Imagine that instead of assuming a fixed probability $\\theta$ for the first coin,\n",
    "we would like to infer the probability from observations.\n",
    "As we have learned in the first sections, this means including the probability into our model as a random varibale and define a joint distribution over $\\theta$, $c_1$, and $c_2$.\n",
    "The model `simple_coins` already tells us how to sample $c_1, c_2 \\mid \\theta$, so all we need is a prior for $\\theta$.\n",
    "We are going to go with the [Beta distribution](https://en.wikipedia.org/wiki/Beta_distribution) for $\\theta$, which is conjugate prior to the Bernoulli distribution in which $\\theta$ is used.\n",
    "Instead of defining this distribution ourselves (which we could do!), we are going to take it from `pyro.distributions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'theta': tensor(0.0249), 'c1': tensor(False), 'c2': False}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyro.distributions import Beta\n",
    "\n",
    "def complicated_coins():\n",
    "    theta = sample(\"theta\", Beta(1,1)) # this is just a uniform distribution between 0 and 1\n",
    "    c1 = sample(\"c1\", Bernoulli(theta))\n",
    "    c2 = sample(\"c2\", Bernoulli(0.9 if c1 else 0.1))\n",
    "\n",
    "clear_rvs()\n",
    "sample_function = sample_sample\n",
    "complicated_coins()\n",
    "rv_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huh! For some reason, using the Beta distribution from pyro makes our random values become some kind of `tensor` thing (at least some of them).\n",
    "We will figure out why in the next section, but for now we can ignore it.\n",
    "\n",
    "Now it's very difficult to obtain a reliable estimate of $\\theta$ from a single observation of $c_2$.\n",
    "In practice, we would have a whole dataset of observations that we can use to infer a parameter that underlies all of them.\n",
    "In this case, for example, we could flip $c_1$ and $c_2$ several times, assuming that the fairness of $c_1$ stays the same.\n",
    "Let's include this idea into our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'theta': tensor(0.8411),\n",
       " 'c1_0': tensor(False),\n",
       " 'c2_0': False,\n",
       " 'c1_1': tensor(True),\n",
       " 'c2_1': False,\n",
       " 'c1_2': tensor(False),\n",
       " 'c2_2': False}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def complicated_coins(n):\n",
    "    # sample theta once\n",
    "    theta = sample(\"theta\", Beta(1,1))\n",
    "    for i in range(n):\n",
    "        c1 = sample(\"c1_{}\".format(i), Bernoulli(theta))\n",
    "        c2 = sample(\"c2_{}\".format(i), Bernoulli(0.9 if c1 else 0.1))\n",
    "\n",
    "clear_rvs()\n",
    "sample_function = sample_sample\n",
    "complicated_coins(3)\n",
    "rv_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this version of `complicated_coins` we can provide an additional parameter `n` that tells us how many coin pairs we flip.\n",
    "Since we want to be able to distinguish the outcomes of each pair, we add an index to `c1` and `c2` indicating the trial.\n",
    "\n",
    "Now to the guide.\n",
    "Since we only want to observe the $c_2$s, we need to provide a guide for both $\\theta$ and the $c_1$ of each trial.\n",
    "For the $c_1$s we already know that we want a Bernoulli distribution,\n",
    "and for $\\theta$ we again choose a beta distribution, which has two parameters $\\alpha$ and $\\beta$.\n",
    "According to the mean-field strategy,\n",
    "we assume the $c_1$s and $\\theta$ to be independent in the posterior, so the guide is\n",
    "\n",
    "$$\n",
    "    q_\\phi(\\vec{c_1}, \\theta) = p(\\theta ;  \\alpha, \\beta) \\prod_i p(c_{1i} ; \\varphi_i),\n",
    "$$\n",
    "\n",
    "and $\\phi = (\\alpha, \\beta, \\vec{\\varphi})$.\n",
    "\n",
    "This is easy enough to write as a program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complicated_coins_guide(n, alpha, beta, c1probs):\n",
    "    sample(\"theta\", Beta(alpha, beta))\n",
    "    for i in range(n):\n",
    "        sample(\"c1_{}\".format(i), Bernoulli(c1probs[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing that is not so nice is that the number of samples and the parameters of the family both appear as function parameters.\n",
    "While `n` is just used to make the model adaptable to the size of the dataset,\n",
    "`alpha`, `beta`, and `c1probs` are parameters that we want to optimize.\n",
    "To make this explicit (and to allow automatic optimization, which will be discussed later),\n",
    "pyro provides another function called `param`, which takes a parameter name and a starting value.\n",
    "It registers the parameter in a parameter store similar to how `sample` registers random variables.\n",
    "We can rewrite our guide to a form that matches the one used in pyro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def params(name, initial_value):\n",
    "    return initial_value # does nothing interesting for now\n",
    "\n",
    "def complicated_coins_guide(n):\n",
    "    # params and distribution for theta\n",
    "    alpha = param(\"alpha\", 1.)\n",
    "    beta  = param(\"beta\",  1.)\n",
    "    sample(\"theta\", Beta(alpha, beta))\n",
    "    # params and distribution for c1\n",
    "    c1probs = param(\"c1probs\", [.5 for _ in n])\n",
    "    for i in range(n):\n",
    "        sample(\"c1_{}\".format(i), Bernoulli(c1probs[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how `complicated_coins_guide` now has the same signature as `complicated_coins`.\n",
    "This makes it easy to ensure that we always generate the same model structure (e.g. the same number of coin flips) in the model and the guide, by defining their arguments once and passing these arguments to both functions.\n",
    "\n",
    "The only thing that is missing now is how `param` works and how we can use it to optimize the parameters of the guide.\n",
    "This will be the topic of the last two sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercises\n",
    "\n",
    "tbd."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Optimization via PyTorch\n",
    "\n",
    "- tensors\n",
    "- autodiff\n",
    "- backprop\n",
    "- optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return 0.5 * x**2 + 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5000)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = f(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.requires_grad = True\n",
    "y = f(x)\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient =  tensor(1.)\n",
      "x =  tensor(0.9000)\n",
      "gradient =  tensor(0.9000)\n",
      "x =  tensor(0.8100)\n",
      "gradient =  tensor(0.8100)\n",
      "x =  tensor(0.7290)\n",
      "gradient =  tensor(0.7290)\n",
      "x =  tensor(0.6561)\n",
      "gradient =  tensor(0.6561)\n",
      "x =  tensor(0.5905)\n",
      "gradient =  tensor(0.5905)\n",
      "x =  tensor(0.5314)\n",
      "gradient =  tensor(0.5314)\n",
      "x =  tensor(0.4783)\n",
      "gradient =  tensor(0.4783)\n",
      "x =  tensor(0.4305)\n",
      "gradient =  tensor(0.4305)\n",
      "x =  tensor(0.3874)\n",
      "gradient =  tensor(0.3874)\n",
      "x =  tensor(0.3487)\n",
      "gradient =  tensor(0.3487)\n",
      "x =  tensor(0.3138)\n",
      "gradient =  tensor(0.3138)\n",
      "x =  tensor(0.2824)\n",
      "gradient =  tensor(0.2824)\n",
      "x =  tensor(0.2542)\n",
      "gradient =  tensor(0.2542)\n",
      "x =  tensor(0.2288)\n",
      "gradient =  tensor(0.2288)\n",
      "x =  tensor(0.2059)\n",
      "gradient =  tensor(0.2059)\n",
      "x =  tensor(0.1853)\n",
      "gradient =  tensor(0.1853)\n",
      "x =  tensor(0.1668)\n",
      "gradient =  tensor(0.1668)\n",
      "x =  tensor(0.1501)\n",
      "gradient =  tensor(0.1501)\n",
      "x =  tensor(0.1351)\n",
      "gradient =  tensor(0.1351)\n",
      "x =  tensor(0.1216)\n",
      "gradient =  tensor(0.1216)\n",
      "x =  tensor(0.1094)\n",
      "gradient =  tensor(0.1094)\n",
      "x =  tensor(0.0985)\n",
      "gradient =  tensor(0.0985)\n",
      "x =  tensor(0.0886)\n",
      "gradient =  tensor(0.0886)\n",
      "x =  tensor(0.0798)\n",
      "gradient =  tensor(0.0798)\n",
      "x =  tensor(0.0718)\n",
      "gradient =  tensor(0.0718)\n",
      "x =  tensor(0.0646)\n",
      "gradient =  tensor(0.0646)\n",
      "x =  tensor(0.0581)\n",
      "gradient =  tensor(0.0581)\n",
      "x =  tensor(0.0523)\n",
      "gradient =  tensor(0.0523)\n",
      "x =  tensor(0.0471)\n",
      "gradient =  tensor(0.0471)\n",
      "x =  tensor(0.0424)\n",
      "gradient =  tensor(0.0424)\n",
      "x =  tensor(0.0382)\n",
      "gradient =  tensor(0.0382)\n",
      "x =  tensor(0.0343)\n",
      "gradient =  tensor(0.0343)\n",
      "x =  tensor(0.0309)\n",
      "gradient =  tensor(0.0309)\n",
      "x =  tensor(0.0278)\n",
      "gradient =  tensor(0.0278)\n",
      "x =  tensor(0.0250)\n",
      "gradient =  tensor(0.0250)\n",
      "x =  tensor(0.0225)\n",
      "gradient =  tensor(0.0225)\n",
      "x =  tensor(0.0203)\n",
      "gradient =  tensor(0.0203)\n",
      "x =  tensor(0.0182)\n",
      "gradient =  tensor(0.0182)\n",
      "x =  tensor(0.0164)\n",
      "gradient =  tensor(0.0164)\n",
      "x =  tensor(0.0148)\n",
      "gradient =  tensor(0.0148)\n",
      "x =  tensor(0.0133)\n",
      "gradient =  tensor(0.0133)\n",
      "x =  tensor(0.0120)\n",
      "gradient =  tensor(0.0120)\n",
      "x =  tensor(0.0108)\n",
      "gradient =  tensor(0.0108)\n",
      "x =  tensor(0.0097)\n",
      "gradient =  tensor(0.0097)\n",
      "x =  tensor(0.0087)\n",
      "gradient =  tensor(0.0087)\n",
      "x =  tensor(0.0079)\n",
      "gradient =  tensor(0.0079)\n",
      "x =  tensor(0.0071)\n",
      "gradient =  tensor(0.0071)\n",
      "x =  tensor(0.0064)\n",
      "gradient =  tensor(0.0064)\n",
      "x =  tensor(0.0057)\n",
      "gradient =  tensor(0.0057)\n",
      "x =  tensor(0.0052)\n",
      "gradient =  tensor(0.0052)\n",
      "x =  tensor(0.0046)\n",
      "gradient =  tensor(0.0046)\n",
      "x =  tensor(0.0042)\n",
      "gradient =  tensor(0.0042)\n",
      "x =  tensor(0.0038)\n",
      "gradient =  tensor(0.0038)\n",
      "x =  tensor(0.0034)\n",
      "gradient =  tensor(0.0034)\n",
      "x =  tensor(0.0030)\n",
      "gradient =  tensor(0.0030)\n",
      "x =  tensor(0.0027)\n",
      "gradient =  tensor(0.0027)\n",
      "x =  tensor(0.0025)\n",
      "gradient =  tensor(0.0025)\n",
      "x =  tensor(0.0022)\n",
      "gradient =  tensor(0.0022)\n",
      "x =  tensor(0.0020)\n",
      "gradient =  tensor(0.0020)\n",
      "x =  tensor(0.0018)\n",
      "gradient =  tensor(0.0018)\n",
      "x =  tensor(0.0016)\n",
      "gradient =  tensor(0.0016)\n",
      "x =  tensor(0.0015)\n",
      "gradient =  tensor(0.0015)\n",
      "x =  tensor(0.0013)\n",
      "gradient =  tensor(0.0013)\n",
      "x =  tensor(0.0012)\n",
      "gradient =  tensor(0.0012)\n",
      "x =  tensor(0.0011)\n",
      "gradient =  tensor(0.0011)\n",
      "x =  tensor(0.0010)\n",
      "gradient =  tensor(0.0010)\n",
      "x =  tensor(0.0009)\n",
      "gradient =  tensor(0.0009)\n",
      "x =  tensor(0.0008)\n",
      "gradient =  tensor(0.0008)\n",
      "x =  tensor(0.0007)\n",
      "gradient =  tensor(0.0007)\n",
      "x =  tensor(0.0006)\n",
      "gradient =  tensor(0.0006)\n",
      "x =  tensor(0.0006)\n",
      "gradient =  tensor(0.0006)\n",
      "x =  tensor(0.0005)\n",
      "gradient =  tensor(0.0005)\n",
      "x =  tensor(0.0005)\n",
      "gradient =  tensor(0.0005)\n",
      "x =  tensor(0.0004)\n",
      "gradient =  tensor(0.0004)\n",
      "x =  tensor(0.0004)\n",
      "gradient =  tensor(0.0004)\n",
      "x =  tensor(0.0003)\n",
      "gradient =  tensor(0.0003)\n",
      "x =  tensor(0.0003)\n",
      "gradient =  tensor(0.0003)\n",
      "x =  tensor(0.0003)\n",
      "gradient =  tensor(0.0003)\n",
      "x =  tensor(0.0002)\n",
      "gradient =  tensor(0.0002)\n",
      "x =  tensor(0.0002)\n",
      "gradient =  tensor(0.0002)\n",
      "x =  tensor(0.0002)\n",
      "gradient =  tensor(0.0002)\n",
      "x =  tensor(0.0002)\n",
      "gradient =  tensor(0.0002)\n",
      "x =  tensor(0.0002)\n",
      "gradient =  tensor(0.0002)\n",
      "x =  tensor(0.0001)\n",
      "gradient =  tensor(0.0001)\n",
      "x =  tensor(0.0001)\n",
      "gradient =  tensor(0.0001)\n",
      "x =  tensor(0.0001)\n",
      "gradient =  tensor(0.0001)\n",
      "x =  tensor(0.0001)\n",
      "gradient =  tensor(0.0001)\n",
      "x =  tensor(9.4046e-05)\n",
      "gradient =  tensor(9.4046e-05)\n",
      "x =  tensor(8.4642e-05)\n",
      "gradient =  tensor(8.4642e-05)\n",
      "x =  tensor(7.6177e-05)\n",
      "gradient =  tensor(7.6177e-05)\n",
      "x =  tensor(6.8560e-05)\n",
      "gradient =  tensor(6.8560e-05)\n",
      "x =  tensor(6.1704e-05)\n",
      "gradient =  tensor(6.1704e-05)\n",
      "x =  tensor(5.5533e-05)\n",
      "gradient =  tensor(5.5533e-05)\n",
      "x =  tensor(4.9980e-05)\n",
      "gradient =  tensor(4.9980e-05)\n",
      "x =  tensor(4.4982e-05)\n",
      "gradient =  tensor(4.4982e-05)\n",
      "x =  tensor(4.0484e-05)\n",
      "gradient =  tensor(4.0484e-05)\n",
      "x =  tensor(3.6435e-05)\n",
      "gradient =  tensor(3.6435e-05)\n",
      "x =  tensor(3.2792e-05)\n",
      "gradient =  tensor(3.2792e-05)\n",
      "x =  tensor(2.9513e-05)\n",
      "gradient =  tensor(2.9513e-05)\n",
      "x =  tensor(2.6561e-05)\n"
     ]
    }
   ],
   "source": [
    "# gradient descent\n",
    "lr = 0.1\n",
    "x = torch.tensor(1., requires_grad=True)\n",
    "for i in range(100):\n",
    "    y = f(x)\n",
    "    y.backward()\n",
    "    print('gradient = ', x.grad)\n",
    "    x.data -= lr * x.grad\n",
    "    print('x = ', x.data)\n",
    "    x.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Variable that requires grad. Use var.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-184-dc8bb7ec1ce9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBernoulli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-138-a8aa94154b37>\u001b[0m in \u001b[0;36mlog_p\u001b[0;34m(self, heads)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlog_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mheads\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mcoin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBernoulli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dateien/dev/python/harmony-model/env/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    490\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Variable that requires grad. Use var.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "dist = Bernoulli(torch.tensor(0.4, requires_grad=True))\n",
    "lp = dist.log_p(True)\n",
    "lp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Lighting the Whole Thing Up\n",
    "\n",
    "- torch + \"sample\" + distributions = pyro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "harmony-model",
   "language": "python",
   "name": "harmony-model"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
