{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyro\n",
    "from pyro.distributions import *\n",
    "#from collections import Counter\n",
    "import pyro.infer\n",
    "import pyro.optim\n",
    "import pyro.util\n",
    "pyro.enable_validation(True)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import scipy.special as special\n",
    "import math\n",
    "\n",
    "import os.path as path\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_rng_state(name):\n",
    "    fn = name + '-' + datetime.today().isoformat() + '.state'\n",
    "    state = pyro.util.get_rng_state()\n",
    "    with open('rng-' + fn, 'w') as f:\n",
    "        print(state, file=f)\n",
    "    torch.save(state['torch'], 'torch-' + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seeds\n",
    "pyro.set_rng_seed(0)\n",
    "#torch.set_deterministic(True)\n",
    "#torch.set_num_threads(1)\n",
    "#torch.set_num_interop_threads(1)\n",
    "\n",
    "# fix the range of pitches we consider\n",
    "fifth_range = 2*7                  # 2 diatonics\n",
    "npcs = 2*fifth_range+1             # around C: Cbb to C## on LoF\n",
    "utils.set_fifth_range(fifth_range) # used to make helper functions work correctly\n",
    "nclusters = 5                      # Try clustering down to how many clusters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Cognitive Model or Harmonic Types\n",
    "\n",
    "## Model\n",
    "\n",
    "A chord consists of a number of notes,\n",
    "which are either generated as stable chord tones or as ornaments.\n",
    "We model this process by distinguishing (for each chord type)\n",
    "a distribution of chord tones and a distribution of ornaments.\n",
    "For each generated note, a coin is flipped as to whether the tone is generated as a chord tone or ornament.\n",
    "The pitch is then drawn from the corresponding distribution.\n",
    "Since we don't always know the type of a note, we flip another coin to decide whether the type is observed or not (in which case `unknown` is emitted for both ornaments and chordtones).\n",
    "\n",
    "Priors:\n",
    "- choose $\\vec\\chi \\sim \\text{Dirichlet}(0.5, n_\\text{harmonies})$\n",
    "- choose $\\lambda \\sim \\text{Gamma}(3,1)$\n",
    "- choose $\\theta_c \\sim \\text{Beta}(1,1)$ for each of $n_\\text{clusters}$ clusters\n",
    "- for each chord type $c$:\n",
    "  - choose $\\xi_c \\sim \\text{Categorical}(n_\\text{clusters})$\n",
    "  - choose $\\vec\\phi_{ct}^{(c)} \\sim \\text{Dirichlet}(0.5, n_\\text{pitches})$\n",
    "  - choose $\\vec\\phi_{or}^{(c)} \\sim \\text{Dirichlet}(0.5, n_\\text{pitches})$\n",
    "\n",
    "Generating a single chord (long version):\n",
    "- choose $h \\sim \\text{Categorical}(\\vec\\chi)$\n",
    "- choose $n \\sim \\text{Poisson}(\\lambda) + 1$\n",
    "- for each note $i \\in 1, \\ldots, n$:\n",
    "  - choose $t_i \\sim \\text{Bernoulli}(\\theta_{\\xi_c})$\n",
    "  - choose $p_i \\sim \\begin{cases}\n",
    "                       \\text{Categorical}(\\vec\\phi_{ct}^{(h)}) & \\text{if } t_i = 1\\\\\n",
    "                       \\text{Categorical}(\\vec\\phi_{or}^{(h)}) & \\text{if } t_i = 0\n",
    "                     \\end{cases}$\n",
    "  - choose $o_i \\sim \\text{Bernoulli}(p_\\text{obs})$\n",
    "  - choose $ot_i = \\begin{cases}\n",
    "                     \\text{'chordtone'} & \\text{if } o_i = 1 \\wedge p_i = 1\\\\\n",
    "                     \\text{'ornament'} & \\text{if } o_i = 1 \\wedge p_i = 0\\\\\n",
    "                     \\text{'unknown'} & \\text{if } o_i = 0\\\\\n",
    "                   \\end{cases}$\n",
    "- count $(p_i,ot_i)$ pairs\n",
    "\n",
    "Generating a single chord (compact version)\n",
    "- choose $h \\sim \\text{Catecorical}(\\vec\\chi)$\n",
    "- choose $n \\sim \\text{Poisson}(\\lambda) + 1$\n",
    "- choose $n_{p,ot} \\sim \\text{Multinomial}(n, \\vec\\nu),$ where\n",
    "  - $\\nu_{ct} = p_\\text{obs} \\cdot \\theta_{\\xi_c} \\cdot \\vec\\phi_{ct}^{(h)}$\n",
    "  - $\\nu_{or} = p_\\text{obs} \\cdot (1-\\theta_{\\xi_c}) \\cdot \\vec\\phi_{or}^{(o)}$\n",
    "  - $\\nu_{uk} = (1-p_\\text{obs}) \\cdot \\left( \\theta_{\\xi_c} \\vec\\phi_{ct}^{(h)} + (1-\\theta_{\\xi_c}) \\vec\\phi_{or}^{(h)} \\right)$\n",
    "  - $\\nu = \\text{concat}(\\nu_{ct}, \\nu_{or}, \\nu_{uk})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chord_model(npcs, nharmonies, nclusters, data, subsamples=500, pobserve=0.5, **kwargs):    \n",
    "    # parameters priors:\n",
    "    # distribution of the harmonies\n",
    "    p_harmony = pyro.sample('p_harmony', Dirichlet(0.5 * torch.ones(nharmonies)))\n",
    "    # each cluster \n",
    "    with pyro.plate('clusters', nclusters) as ind:\n",
    "        # distribution of ornament probability\n",
    "        p_is_chordtone = pyro.sample('p_is_chordtone', Beta(1,1))\n",
    "    # distribution of notes in the harmonies\n",
    "    with pyro.plate('harmonies', nharmonies) as ind:\n",
    "        cluster = pyro.sample('cluster', Categorical(torch.ones(nclusters)))\n",
    "        p_is_chordtone_c = p_is_chordtone[cluster]\n",
    "        #print(p_is_chordtone.shape)\n",
    "        # distribution of notes per note type\n",
    "        p_chordtones = pyro.sample('p_chordtones', Dirichlet(0.5 * torch.ones(npcs)))\n",
    "        p_ornaments  = pyro.sample('p_ornaments', Dirichlet(0.5 * torch.ones(npcs)))\n",
    "        #print(p_chordtones.shape)\n",
    "        # we build a big categorical out of the chordtones and ornaments,\n",
    "        # including notes of unknown type (marginalizing over the categories)\n",
    "        #p_ct = p_is_chordtone_c       * p_chordtones\n",
    "        #p_or = (1 - p_is_chordtone_c) * p_ornaments\n",
    "        p_ct = torch.mm(torch.diag(p_is_chordtone_c), p_chordtones)\n",
    "        p_or = torch.mm(torch.diag(1 - p_is_chordtone_c), p_ornaments)\n",
    "        p_unobserved = p_ct + p_or\n",
    "        p_tones = torch.cat([pobserve * p_ct, pobserve * p_or, (1-pobserve) * p_unobserved], dim=1)\n",
    "    # distribution of note rate in chords\n",
    "    rate_notes = pyro.sample('rate_notes', Gamma(3,1))\n",
    "    \n",
    "    # sampling the data:\n",
    "    nchords = len(data['c'])\n",
    "    subs = min(nchords,subsamples) if subsamples != None else None\n",
    "    with pyro.plate('data', nchords, subsample_size=subs) as ind:\n",
    "        # pick a harmony\n",
    "        c = pyro.sample('c', Categorical(p_harmony), obs=data['c'][ind])\n",
    "        # pick a number of notes\n",
    "        nnotes = 1 + pyro.sample('n', Poisson(rate_notes), obs=data['n'][ind]).int()\n",
    "        # sample chordtones\n",
    "        # Normally we would sample nnotes notes for each chord, but that doesn't work vectorized.\n",
    "        # However, evaluating the probability ignores n, so we can just provide 1 here.\n",
    "        notes = pyro.sample('chord', Multinomial(1, p_tones[c], validate_args=False), obs=data['notes'][ind])\n",
    "        chords = {'c': c,\n",
    "                  'n': nnotes,\n",
    "                  'counts': notes.reshape(-1,npcs)}\n",
    "    return chords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guide\n",
    "\n",
    "A simple guide that assumes the latent variables to be distributed independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chord_guide(npcs, nharmonies, nclusters, data, subsamples=500, pobserve=0.5, init=dict()):\n",
    "\n",
    "    \n",
    "    # posterior of p_harmony\n",
    "    params_p_harmony = pyro.param('params_p_harmony',\n",
    "                                  init['harmonies'] if 'harmonies' in init else 0.5 * torch.ones(nharmonies),\n",
    "                                  constraint=constraints.positive)\n",
    "    pyro.sample('p_harmony', Dirichlet(params_p_harmony))\n",
    "    \n",
    "    # posteriors of notes dists in harmonies (parameters)\n",
    "    params_p_chordtones = pyro.param('params_p_chordtones',\n",
    "                                     init['chordtones'] if  'chordtones' in init else 0.5 * torch.ones(nharmonies, npcs),\n",
    "                                     constraint=constraints.positive)\n",
    "    params_p_ornaments = pyro.param('params_p_ornaments',\n",
    "                                     init['ornaments'] if 'ornaments' in init else 0.5 * torch.ones(nharmonies, npcs),\n",
    "                                    constraint=constraints.positive)\n",
    "    \n",
    "    # posterior of ornament probability (parameters)\n",
    "    alpha_p_ict = pyro.param('alpha_p_ict',\n",
    "                             init['is_ct'] if 'is_ct' in init else torch.ones(nclusters),\n",
    "                             constraint=constraints.positive)\n",
    "    beta_p_ict = pyro.param('beta_p_ict',\n",
    "                            init['is_or'] if 'is_or' in init else torch.ones(nclusters),\n",
    "                            constraint=constraints.positive)\n",
    "    \n",
    "    params_cluster = pyro.param('params_cluster', \n",
    "                          init['cluster'] if 'cluster' in init else\n",
    "                          torch.ones(nharmonies, nclusters)/nclusters,\n",
    "                          constraint = constraints.simplex)\n",
    "    \n",
    "    with pyro.plate('clusters', nclusters) as ind:\n",
    "        pyro.sample('p_is_chordtone', Beta(alpha_p_ict, beta_p_ict))\n",
    "        \n",
    "    # posteriors of ornament probability and note distributions\n",
    "    with pyro.plate('harmonies', nharmonies) as ind:\n",
    "        pyro.sample('cluster', Categorical(params_cluster))\n",
    "        pyro.sample('p_chordtones', Dirichlet(params_p_chordtones))\n",
    "        pyro.sample('p_ornaments', Dirichlet(params_p_ornaments))\n",
    "        \n",
    "    #posterior of note rate\n",
    "    alpha_rate_notes = pyro.param('alpha_rate_notes',\n",
    "                                  init['sum_chords'] if 'sum_chords' in init else torch.tensor(3.),\n",
    "                                  constraint=constraints.positive)\n",
    "    beta_rate_notes = pyro.param('beta_rate_notes',\n",
    "                                 init['n_chords'] if 'n_chords' in init else torch.tensor(1.),\n",
    "                                 constraint=constraints.positive)\n",
    "    rate_notes = pyro.sample('rate_notes', Gamma(alpha_rate_notes, beta_rate_notes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and Conditioning\n",
    "\n",
    "### Data Format\n",
    "\n",
    "The input data (i.e. the observations that the model is conditioned on) is represented by three tensors:\n",
    "- `c` for the chord labels (as \"categorical\" integers)\n",
    "- `n` for the number of notes in each chord\n",
    "- `notes` for the observed notes in each chord\n",
    "\n",
    "Each of these tensors represents the values for all chords at the same time (i.e. a *vectorized* representation),\n",
    "so the first dimension of each equals `nchords`, the number of chords.\n",
    "`c` and `n` are vectors, i.e. their value for each chord is a scalar.\n",
    "`notes` represents a vector for each chord that contains the counts of all pitch $\\times$ note type pairs in the chord.\n",
    "If we assume 29 pitch classes, we therefore have 87 entries: 29 for the chordtones, 29 for the ornaments, and 29 for the notes of unknown type.\n",
    "As a result, `notes` has dimension `nchords` $\\times$ 87.\n",
    "\n",
    "The values of `c` represent each chord's type, which is distributed according to a categorical distribution.\n",
    "In pyro/torch, categories are represented as integers, so we must convert textual labels into integers.\n",
    "Similarly, the index of a note in `notes` is determined by it's pitch class and type (as outlined above).\n",
    "While we allow negative pitch classes, they can be easily transformed into indices (and *vice versa*) by shifting all values by `npcs // 2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chord_tensor(notes):\n",
    "    \"\"\"Takes a list of notes as (fifth, type) pairs and returns a vector of counts.\"\"\"\n",
    "    notetype = {'chordtone': 0, 'ornament': 1, 'unknown': 2}\n",
    "    chord = torch.zeros((3, npcs))\n",
    "    for (fifth, t) in notes:\n",
    "        chord[notetype[t], utils.fifth_to_index(fifth)] += 1\n",
    "    return chord\n",
    "\n",
    "def annot_data_obs(chords):\n",
    "    \"\"\"Helper function to turn a list of chord dictionary into a dictionary of observation vectors.\"\"\"\n",
    "    obs = {}\n",
    "    obs[\"notes\"] = torch.cat([chord_tensor(c['notes']).reshape((1,-1)) for c in chords], dim=0)\n",
    "    obs[\"c\"] = torch.tensor([c['label'] for c in chords])\n",
    "    obs[\"n\"] = torch.tensor([len(c['notes']) - 1. for c in chords])\n",
    "    return obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Dataset\n",
    "\n",
    "The data is loaded from a TSV file that.\n",
    "The resulting dataframe is converted to the observation format that we pass to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filename):\n",
    "    print(\"loading dataset...\") \n",
    "    df = utils.load_csv(filename)\n",
    "    sizes = df.groupby(['chordid', 'label']).size()\n",
    "    type_counts = sizes.groupby('label').size().sort_values(ascending=False)\n",
    "    chordtypes = type_counts.index.tolist()\n",
    "    df['numlabel'] = df.label.map(chordtypes.index)\n",
    "    \n",
    "    # check if precomputed tensor data is available:\n",
    "    prefn = filename + \"_precomp.pt\"\n",
    "    if path.exists(prefn) and path.getmtime(prefn) > path.getmtime(filename):\n",
    "        print(\"using precomputed tensor data.\")\n",
    "        obs = torch.load(prefn)\n",
    "    else:\n",
    "        print('extracting chords...')\n",
    "        chords = [{'label': label, 'notes': list(zip(grp.fifth, grp.type))}\n",
    "                  for (_, label), grp in tqdm.tqdm(df.groupby(['chordid', 'numlabel']))]\n",
    "        print('converting chords to tensors...')\n",
    "        obs = annot_data_obs(chords)\n",
    "        torch.save(obs, prefn)\n",
    "    \n",
    "    print(len(chordtypes), \"chord types\")\n",
    "    print(len(obs[\"c\"]), \"chords\")\n",
    "    return df, obs, chordtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clust_dist(X,Y):\n",
    "    return 1 - (special.beta((X[0] + Y[0]) / 2, (X[1] + Y[1]) /2)) / math.sqrt(special.beta(X[0],X[1]) * special.beta(Y[0],Y[1]))\n",
    "        \n",
    "        \n",
    "def get_init_params(df, nharms, npcs, nclusters):\n",
    "    init = dict()\n",
    "    \n",
    "    init['harmonies'] = torch.tensor(df.groupby('numlabel').size().sort_values(ascending=False)) + 0.5\n",
    "\n",
    "    init['chordtones'] = torch.zeros([nharms,npcs]) + 0.5\n",
    "    for (numlabel, fifth), grp in df[df.type=='chordtone'].groupby(['numlabel','fifth']):\n",
    "        init['chordtones'][numlabel, utils.fifth_to_index(fifth)] += grp.fifth.count()\n",
    "\n",
    "    init['ornaments'] = torch.zeros([nharms,npcs]) + 0.5\n",
    "    for (numlabel, fifth), grp in df[df.type=='ornament'].groupby(['numlabel','fifth']):\n",
    "        init['ornaments'][numlabel, utils.fifth_to_index(fifth)] += grp.fifth.count()\n",
    "    \n",
    "    is_ct_harms = torch.tensor([sum(df[df.numlabel==l].type=='chordtone') for l in range(nharms)])\n",
    "    #torch.tensor(sum(df.type=='chordtone') + 1)\n",
    "    is_or_harms = torch.tensor([sum(df[df.numlabel==l].type=='ornament') for l in range(nharms)])\n",
    "    #torch.tensor(sum(df.type=='ornament') + 1)\n",
    "    # Do cluster assignment\n",
    "    cluster_assignment = dict((k,k) for k in range(nharms))\n",
    "    clusters = dict((k,(is_ct_harms[k], is_or_harms[k])) for k in range(nharms))\n",
    "    for it in range(nharms - nclusters):\n",
    "        # compute pairwise distances\n",
    "        cs = list(clusters.items())\n",
    "        n = len(cs)\n",
    "        dists = dict()\n",
    "        for i in range(n):\n",
    "            for j in range(i+1,n):\n",
    "                dists[(cs[i][0],cs[j][0])] = clust_dist(cs[i][1], cs[j][1])\n",
    "\n",
    "        # find minimal pair\n",
    "        min1, min2 = min(dists, key=dists.get)\n",
    "        # merge pair\n",
    "        new_key = min1\n",
    "        new_cluster = (clusters[min1][0] + clusters[min2][0],\n",
    "                       clusters[min1][1] + clusters[min2][1])\n",
    "        clusters.pop(min1)\n",
    "        clusters.pop(min2)\n",
    "        clusters[new_key] = new_cluster\n",
    "        cluster_assignment = dict((k, new_key if v in [min1,min2] else v) for k,v in cluster_assignment.items())\n",
    "    \n",
    "    \n",
    "    # Estimate cluster parameters\n",
    "    init['is_ct'] = torch.tensor(list(map(lambda i: i[1][0], clusters.items())))\n",
    "    init['is_or'] = torch.tensor(list(map(lambda i: i[1][1], clusters.items())))\n",
    "    \n",
    "    chord_sizes = df.groupby('chordid').size()-1\n",
    "    init['sum_chords'] = torch.tensor(sum(chord_sizes) + 3)\n",
    "    init['n_chords'] = torch.tensor(len(chord_sizes) + 1)\n",
    "    return init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After inferring the parameters we save them for easier inspection and reuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_params(params, chordtypes, name):\n",
    "    torch.save(params, name+'.pt')\n",
    "    with open(name+'.json', 'w') as f:\n",
    "        json.dump({'params': {key: val.tolist() for key,val in params.items()},\n",
    "                   'chordtypes': chordtypes},\n",
    "                  f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "Inference of the posterior is done via variational inference, i.e. by optimizing the parameters of the guide.\n",
    "The function `infer_posteriors` takes a dataset of observations,\n",
    "performs the optimization, and returns the optimized parameters together with some of their histories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def infer_posteriors(obs, init, chordtypes, nclusters,\n",
    "                     nsteps=5_000, subsamples=10_000, particles=1,\n",
    "                     plot_loss=True, save_as=None):\n",
    "    # optimize the parameters of the guide\n",
    "    pyro.clear_param_store()\n",
    "    pyro.set_rng_seed(1625) # set every time for independent reproducibility\n",
    "    svi = pyro.infer.SVI(model=chord_model,\n",
    "                         guide=chord_guide,\n",
    "                         optim=pyro.optim.Adam({\"lr\": 0.01, \"betas\": (0.95, 0.999)}),\n",
    "                         #optim=pyro.optim.Adadelta({\"lr\": 1.0, \"rho\": 0.9}),\n",
    "                         #optim=pyro.optim.SGD({\"lr\": 0.00005, \"momentum\": 0.9, \"nesterov\": True}),\n",
    "                         loss=pyro.infer.Trace_ELBO(num_particles=particles))\n",
    "\n",
    "    nharms = len(chordtypes)\n",
    "    \n",
    "    # set up histories for the loss and some of the parameters\n",
    "    losses = np.zeros(nsteps)\n",
    "    param_history = {name:np.zeros(nsteps) for name in ['alpha_rate_notes', 'beta_rate_notes']}#, 'alpha_p_ict', 'beta_p_ict']}\n",
    "    root_history = np.zeros((nsteps,nharms))\n",
    "    harm_history = np.zeros((nsteps,nharms))\n",
    "\n",
    "    # run the optimization\n",
    "    for i in tqdm.trange(nsteps):\n",
    "        # update parameters and record loss\n",
    "        losses[i] = svi.step(npcs, nharms, nclusters, obs, subsamples, init=init)\n",
    "        \n",
    "        # record values of some parameters\n",
    "        ps = pyro.get_param_store()\n",
    "        root_history[i] = ps.get_param('params_p_chordtones').detach()[:,fifth_range]\n",
    "        harm_history[i] = ps.get_param('params_p_harmony').detach()\n",
    "        for (name, value) in ps.items():\n",
    "            if name in param_history:\n",
    "                param_history[name][i] = value.item()\n",
    "\n",
    "    # plot the loss\n",
    "    if plot_loss:\n",
    "        plt.figure()\n",
    "        plt.plot(losses)\n",
    "        plt.xlabel(\"iteration\")\n",
    "        plt.ylabel(\"loss\")\n",
    "        plt.show()\n",
    "        print(\"loss variance (last 100 steps):\", losses[-100:].var())\n",
    "    \n",
    "    params = dict((name, value.detach().numpy()) for name, value in pyro.get_param_store().items())\n",
    "    if save_as != None:\n",
    "        save_params(params, chordtypes, save_as)\n",
    "    \n",
    "    return params, param_history, root_history, harm_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To inspect the results and the behaviour of the optimization, we define some functions for plotting parameter histories and posterior distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histories\n",
    "\n",
    "def plot_param_history(history):\n",
    "    df = pd.DataFrame(history)\n",
    "    df.plot()\n",
    "    plt.xlabel(\"iteration\")\n",
    "    plt.show()\n",
    "    \n",
    "def plot_roots(root_history, ylabel='root parameters'):\n",
    "    plt.plot(root_history)\n",
    "    plt.xlabel(\"iteration\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()\n",
    "\n",
    "def plot_histories(param_history, root_history, harm_history):\n",
    "    plot_param_history(param_history)\n",
    "    plot_roots(root_history)\n",
    "    plot_roots(harm_history, ylabel='chord type parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# posteriors\n",
    "\n",
    "# posterior of 'rate_notes'\n",
    "def plot_note_rate(params, lower=0, upper=10):\n",
    "    alpha = params['alpha_rate_notes']\n",
    "    beta = params['beta_rate_notes']\n",
    "    print(alpha)\n",
    "    print(beta)\n",
    "    x = np.linspace(lower, upper, 200)\n",
    "    y = stats.gamma.pdf(x, alpha, scale=1/beta)\n",
    "    plt.plot(x,y)\n",
    "    plt.xlabel('rate_notes')\n",
    "    plt.show()\n",
    "    xrate = torch.linspace(0,10,11)\n",
    "    yrate = stats.nbinom.pmf(xrate, alpha, 1/(1+1/beta))\n",
    "    plt.bar(xrate+1, yrate)\n",
    "    plt.xlabel('nnotes')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_note_rates(phist, n=100, lower=0, upper=10):\n",
    "    alphas = phist['alpha_rate_notes'][-n:]\n",
    "    betas = phist['beta_rate_notes'][-n:]\n",
    "    x = np.linspace(lower, upper, 200)\n",
    "    ys = np.array([stats.gamma.pdf(x, a, scale=1/b) for (a,b) in zip(alphas,betas)]).transpose()\n",
    "    plt.plot(x,ys, color='steelblue', alpha=0.5)\n",
    "    plt.xlabel('rate_notes')\n",
    "    plt.show()\n",
    "    \n",
    "# posterior of 'p_is_chordtone'\n",
    "def plot_p_ict(params, harmtypes, lower=0, upper=1):\n",
    "    alphas = params[\"alpha_p_ict\"]\n",
    "    betas  = params[\"beta_p_ict\"]\n",
    "    x = torch.linspace(lower, upper, 200)\n",
    "    y = np.array([stats.beta.pdf(x, a, b) for a, b in zip(alphas, betas)]).transpose()\n",
    "    plt.plot(x,y)\n",
    "    plt.xlabel(\"p_is_chordtone\")\n",
    "    plt.legend(harmtypes, bbox_to_anchor=(1., 1), loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "# posterior of chord type probabilities\n",
    "def plot_chord_type_dist(params, labels):\n",
    "    plt.figure(figsize=(6,9))\n",
    "    alphas = params['params_p_harmony']\n",
    "    plt.barh(np.arange(len(alphas)), alphas, tick_label=labels)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.xlabel(\"params_p_harmony\")\n",
    "    plt.show()\n",
    "\n",
    "# posteriors of note probabilities\n",
    "def plot_chords(params, labels):\n",
    "    post_chordtones = params['params_p_chordtones']\n",
    "    post_ornaments = params['params_p_ornaments']\n",
    "    for i, name in enumerate(labels):\n",
    "        utils.plot_profile(post_chordtones[i], post_ornaments[i], name)\n",
    "        utils.play_chord(post_chordtones[i])\n",
    "\n",
    "# plot all posteriors\n",
    "def plot_posteriors(params, chordtypes):\n",
    "    plot_note_rate(params)\n",
    "    plot_p_ict(params, chordtypes)\n",
    "    plot_chord_type_dist(params, chordtypes)\n",
    "    plot_chords(params, chordtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "\n",
    "### DCML Corpus\n",
    "\n",
    "The DCML corpus is a collection of classical pieces with elaborate harmonic annotations.\n",
    "Here we only distinguish the basic harmonic types defined in the annotation standard (triads and seventh chords),\n",
    "since the extra information (inversion, suspensions, added notes etc.) do not change the type of the chord."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset...\n",
      "using precomputed tensor data.\n",
      "14 chord types\n",
      "157046 chords\n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset\n",
    "dcml_df, dcml_obs, dcml_chordtypes = load_dataset('data/dcml.tsv')\n",
    "dcml_inits = list(map(lambda nclusters: get_init_params(dcml_df, len(dcml_chordtypes), npcs, nclusters), range(1,15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/350 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'log'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-54a3df1b5724>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdcml_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdcml_inits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     dcml_params, dhist, droots, dharm = infer_posteriors(dcml_obs, dcml_inits[i], dcml_chordtypes, nclusters,\n\u001b[0m\u001b[1;32m      5\u001b[0m                                                      \u001b[0mnsteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m350\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsamples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparticles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                                      save_as=\"dcml_params\"+str(1))\n",
      "\u001b[0;32m<ipython-input-10-5e4f5166476f>\u001b[0m in \u001b[0;36minfer_posteriors\u001b[0;34m(obs, init, chordtypes, nclusters, nsteps, subsamples, particles, plot_loss, save_as)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnsteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# update parameters and record loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnharms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnclusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# record values of some parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyro/infer/svi.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# get loss and compute gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mparam_capture\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_and_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         params = set(site[\"value\"].unconstrained()\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyro/infer/trace_elbo.py\u001b[0m in \u001b[0;36mloss_and_grads\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# grab a trace from the generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmodel_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide_trace\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_traces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m             \u001b[0mloss_particle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msurrogate_loss_particle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_differentiable_loss_particle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_particle\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_particles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyro/infer/elbo.py\u001b[0m in \u001b[0;36m_get_traces\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_particles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyro/infer/trace_elbo.py\u001b[0m in \u001b[0;36m_get_trace\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0magainst\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \"\"\"\n\u001b[0;32m---> 52\u001b[0;31m         model_trace, guide_trace = get_importance_trace(\n\u001b[0m\u001b[1;32m     53\u001b[0m             \"flat\", self.max_plate_nesting, model, guide, args, kwargs)\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_validation_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyro/infer/enum.py\u001b[0m in \u001b[0;36mget_importance_trace\u001b[0;34m(graph_type, max_plate_nesting, model, guide, args, kwargs, detach)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mand\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mrun\u001b[0m \u001b[0magainst\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \"\"\"\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mguide_trace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mguide_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyro/poutine/trace_messenger.py\u001b[0m in \u001b[0;36mget_trace\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mCalls\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mpoutine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0mits\u001b[0m \u001b[0mtrace\u001b[0m \u001b[0minstead\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \"\"\"\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsngr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyro/poutine/trace_messenger.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m                                       args=args, kwargs=kwargs)\n\u001b[1;32m    164\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-b312549048d6>\u001b[0m in \u001b[0;36mchord_guide\u001b[0;34m(npcs, nharmonies, nclusters, data, subsamples, pobserve, init)\u001b[0m\n\u001b[1;32m     24\u001b[0m                             constraint=constraints.positive)\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     params_cluster = pyro.param('params_cluster', \n\u001b[0m\u001b[1;32m     27\u001b[0m                           \u001b[0minit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cluster'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'cluster'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minit\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                           \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnharmonies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnclusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnclusters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyro/primitives.py\u001b[0m in \u001b[0;36mparam\u001b[0;34m(name, *args, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \"\"\"\n\u001b[1;32m     60\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyro/poutine/runtime.py\u001b[0m in \u001b[0;36m_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    261\u001b[0m             }\n\u001b[1;32m    262\u001b[0m             \u001b[0;31m# apply the stack and return its return value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m             \u001b[0mapply_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0m_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_effectful\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyro/poutine/runtime.py\u001b[0m in \u001b[0;36mapply_stack\u001b[0;34m(initial_msg)\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0mdefault_process_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpointer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyro/poutine/runtime.py\u001b[0m in \u001b[0;36mdefault_process_message\u001b[0;34m(msg)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m     \u001b[0mmsg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fn\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"args\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"kwargs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;31m# after fn has been called, update msg to prevent it from being called again.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyro/params/param_store.py\u001b[0m in \u001b[0;36mget_param\u001b[0;34m(self, name, init_tensor, constraint, event_dim)\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyro/params/param_store.py\u001b[0m in \u001b[0;36msetdefault\u001b[0;34m(self, name, init_constrained_value, constraint)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0;31m# set the initial value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_constrained_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;31m# get the param, which is guaranteed to exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyro/params/param_store.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, name, new_constrained_value)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;31m# FIXME should we .detach() the new_constrained_value?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0munconstrained_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_constrained_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m             \u001b[0munconstrained_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munconstrained_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0munconstrained_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/distributions/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inv_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlog_abs_det_jacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/distributions/transforms.py\u001b[0m in \u001b[0;36m_inv_call\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \"\"\"\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache_size\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mx_old\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_old\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_x_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0my_old\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/distributions/transforms.py\u001b[0m in \u001b[0;36m_inverse\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_inverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'log'"
     ]
    }
   ],
   "source": [
    "# run the optimization\n",
    "dcml_outputs = list(dict())\n",
    "for i in range(len(dcml_inits)):\n",
    "    dcml_params, dhist, droots, dharm = infer_posteriors(dcml_obs, dcml_inits[i], dcml_chordtypes, nclusters,\n",
    "                                                     nsteps=350, subsamples=None, particles=1,\n",
    "                                                     save_as=\"dcml_params\"+str(1))\n",
    "    dcml_outputs.append(dict({\n",
    "        \"dcml_params\": dcml_params,\n",
    "        \"dhist\": dhist,\n",
    "        \"droots\": droots,\n",
    "        \"dharm\": dharm,        \n",
    "    }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot the histories the parameters to check convergence\n",
    "for output in dcml_outputs:\n",
    "    plot_histories(output['dhist'], output['droots'], output['dharm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for output in dcml_outputs:\n",
    "    # plot the posterior distributions of the parameters\n",
    "    plot_note_rate(output['dcml_params'], lower=5.5, upper=5.65)\n",
    "    plot_note_rates(output['dhist'], n=50, lower=5.5, upper=5.65)\n",
    "    plot_p_ict(output['dcml_params'], dcml_chordtypes, lower=0.7, upper=0.95)\n",
    "    plot_chord_type_dist(output['dcml_params'], dcml_chordtypes)\n",
    "    plot_chords(output['dcml_params'], dcml_chordtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wikifonia Corpus\n",
    "\n",
    "The Wikifonia dataset consists of leadsheets, i.e. melodies and chord labels.\n",
    "It uses the chord types set in the MusicXML source of the chord-labels, which can be quite chaotic.\n",
    "Therefore, we normalize the chord-types to the ones defined in the MusicXML standard,\n",
    "removing unclear chord labels (which are rather rare)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset...\n",
      "using precomputed tensor data.\n",
      "24 chord types\n",
      "257625 chords\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([339087, 220639, 119740,  79974,  31183,  16626,  16125,   8813,   7902,\n",
       "           5700,   5345,   4306,   3809,   3082,   2812,   2604,   2206,   1048,\n",
       "            841,    805,    622,    517,    149,     30], dtype=torch.int32),\n",
       " tensor([339087, 220639, 119740,  79974,  31183,  16626,  16125,   8813,   7902,\n",
       "           5700,   5345,   4306,   3809,   3082,   2812,   2604,   2206,   1048,\n",
       "            841,    805,    622,    517,    149,     30], dtype=torch.int32),\n",
       " tensor([339087, 220639, 119740,  79974,  31183,  16626,  16125,   8813,   7902,\n",
       "           5700,   5345,   4306,   3809,   3082,   2812,   2604,   2206,   1048,\n",
       "            841,    805,    622,    517,    149,     30], dtype=torch.int32),\n",
       " tensor([339087, 220639, 119740,  79974,  31183,  16626,  16125,   8813,   7902,\n",
       "           5700,   5345,   4306,   3809,   3082,   2812,   2604,   2206,   1048,\n",
       "            841,    805,    622,    517,    149,     30], dtype=torch.int32),\n",
       " tensor([339087, 220639, 119740,  79974,  31183,  16626,  16125,   8813,   7902,\n",
       "           5700,   5345,   4306,   3809,   3082,   2812,   2604,   2206,   1048,\n",
       "            841,    805,    622,    517,    149,     30], dtype=torch.int32),\n",
       " tensor([339087, 220639, 119740,  79974,  31183,  16626,  16125,   8813,   7902,\n",
       "           5700,   5345,   4306,   3809,   3082,   2812,   2604,   2206,   1048,\n",
       "            841,    805,    622,    517,    149,     30], dtype=torch.int32),\n",
       " tensor([339087, 220639, 119740,  79974,  31183,  16626,  16125,   8813,   7902,\n",
       "           5700,   5345,   4306,   3809,   3082,   2812,   2604,   2206,   1048,\n",
       "            841,    805,    622,    517,    149,     30], dtype=torch.int32),\n",
       " tensor([339087, 220639, 119740,  79974,  31183,  16626,  16125,   8813,   7902,\n",
       "           5700,   5345,   4306,   3809,   3082,   2812,   2604,   2206,   1048,\n",
       "            841,    805,    622,    517,    149,     30], dtype=torch.int32),\n",
       " tensor([339087, 220639, 119740,  79974,  31183,  16626,  16125,   8813,   7902,\n",
       "           5700,   5345,   4306,   3809,   3082,   2812,   2604,   2206,   1048,\n",
       "            841,    805,    622,    517,    149,     30], dtype=torch.int32),\n",
       " tensor([339087, 220639, 119740,  79974,  31183,  16626,  16125,   8813,   7902,\n",
       "           5700,   5345,   4306,   3809,   3082,   2812,   2604,   2206,   1048,\n",
       "            841,    805,    622,    517,    149,     30], dtype=torch.int32),\n",
       " tensor([339087, 220639, 119740,  79974,  31183,  16626,  16125,   8813,   7902,\n",
       "           5700,   5345,   4306,   3809,   3082,   2812,   2604,   2206,   1048,\n",
       "            841,    805,    622,    517,    149,     30], dtype=torch.int32),\n",
       " tensor([339087, 220639, 119740,  79974,  31183,  16626,  16125,   8813,   7902,\n",
       "           5700,   5345,   4306,   3809,   3082,   2812,   2604,   2206,   1048,\n",
       "            841,    805,    622,    517,    149,     30], dtype=torch.int32),\n",
       " tensor([339087, 220639, 119740,  79974,  31183,  16626,  16125,   8813,   7902,\n",
       "           5700,   5345,   4306,   3809,   3082,   2812,   2604,   2206,   1048,\n",
       "            841,    805,    622,    517,    149,     30], dtype=torch.int32),\n",
       " tensor([339087, 220639, 119740,  79974,  31183,  16626,  16125,   8813,   7902,\n",
       "           5700,   5345,   4306,   3809,   3082,   2812,   2604,   2206,   1048,\n",
       "            841,    805,    622,    517,    149,     30], dtype=torch.int32),\n",
       " tensor([339087, 220639, 119740,  79974,  31183,  16626,  16125,   8813,   7902,\n",
       "           5700,   5345,   4306,   3809,   3082,   2812,   2604,   2206,   1048,\n",
       "            841,    805,    622,    517,    149,     30], dtype=torch.int32),\n",
       " tensor([339087, 220639, 119740,  79974,  31183,  16626,  16125,   8813,   7902,\n",
       "           5700,   5345,   4306,   3809,   3082,   2812,   2604,   2206,   1048,\n",
       "            841,    805,    622,    517,    149,     30], dtype=torch.int32),\n",
       " tensor([339087, 220639, 119740,  79974,  31183,  16626,  16125,   8813,   7902,\n",
       "           5700,   5345,   4306,   3809,   3082,   2812,   2604,   2206,   1048,\n",
       "            841,    805,    622,    517,    149,     30], dtype=torch.int32),\n",
       " tensor([339087, 220639, 119740,  79974,  31183,  16626,  16125,   8813,   7902,\n",
       "           5700,   5345,   4306,   3809,   3082,   2812,   2604,   2206,   1048,\n",
       "            841,    805,    622,    517,    149,     30], dtype=torch.int32),\n",
       " tensor([339087, 220639, 119740,  79974,  31183,  16626,  16125,   8813,   7902,\n",
       "           5700,   5345,   4306,   3809,   3082,   2812,   2604,   2206,   1048,\n",
       "            841,    805,    622,    517,    149,     30], dtype=torch.int32),\n",
       " tensor([339087, 220639, 119740,  79974,  31183,  16626,  16125,   8813,   7902,\n",
       "           5700,   5345,   4306,   3809,   3082,   2812,   2604,   2206,   1048,\n",
       "            841,    805,    622,    517,    149,     30], dtype=torch.int32),\n",
       " tensor([339087, 220639, 119740,  79974,  31183,  16626,  16125,   8813,   7902,\n",
       "           5700,   5345,   4306,   3809,   3082,   2812,   2604,   2206,   1048,\n",
       "            841,    805,    622,    517,    149,     30], dtype=torch.int32),\n",
       " tensor([339087, 220639, 119740,  79974,  31183,  16626,  16125,   8813,   7902,\n",
       "           5700,   5345,   4306,   3809,   3082,   2812,   2604,   2206,   1048,\n",
       "            841,    805,    622,    517,    149,     30], dtype=torch.int32),\n",
       " tensor([339087, 220639, 119740,  79974,  31183,  16626,  16125,   8813,   7902,\n",
       "           5700,   5345,   4306,   3809,   3082,   2812,   2604,   2206,   1048,\n",
       "            841,    805,    622,    517,    149,     30], dtype=torch.int32)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare the dataset\n",
    "wiki_df, wiki_obs, wiki_chordtypes = load_dataset('data/wikifonia.tsv')\n",
    "wiki_inits = list(map(lambda nclusters: get_init_params(wiki_df, len(wiki_chordtypes), npcs, nclusters), range(1,24)))\n",
    "list(map(lambda wiki_init: wiki_init['harmonies'].int(), wiki_inits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the optimization\n",
    "wiki_outputs = list(dict())\n",
    "for i in range(len(dcml_inits)):\n",
    "    wiki_params, whist, wroots, wharm = infer_posteriors(wiki_obs, wiki_inits[i], wiki_chordtypes, nclusters\n",
    "                                                     nsteps=350, subsamples=None, particles=1,\n",
    "                                                     save_as=\"wikifonia_params\"+str(i))    \n",
    "    wiki_outputs.append(dict({\n",
    "        \"wiki_params\": wiki_params,\n",
    "        \"whist\": whist,\n",
    "        \"wroots\": wroots,\n",
    "        \"wharm\": wharm,        \n",
    "    }))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the histories the parameters to check convergence\n",
    "for output in wiki_outputs:\n",
    "    plot_histories(output['whist'], output['wroots'], output['wharm'])\n",
    "#    plot_histories(whist, wroots, wharm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot the posterior distributions of the parameters\n",
    "for output in wiki_outputs:\n",
    "    # plot the posterior distributions of the parameters\n",
    "    plot_note_rate(output['wiki_params'], lower=2.35, upper=2.45)\n",
    "    plot_note_rates(output['whist'], n=50, lower=2.35, upper=2.45)\n",
    "    plot_p_ict(output['wiki_params'], wiki_chordtypes, lower=0.65, upper=0.95)\n",
    "    plot_chord_type_dist(output['wiki_params'], wiki_chordtypes)\n",
    "    plot_chords(output['wiki_params'], wiki_chordtypes)\n",
    "#plot_note_rate(wiki_params, lower=2.35, upper=2.45)\n",
    "#plot_note_rates(whist, n=100, lower=2.35, upper=2.45)\n",
    "#plot_p_ict(wiki_params, wiki_chordtypes, lower=0.65, upper=0.95)\n",
    "#plot_chord_type_dist(wiki_params, wiki_chordtypes)\n",
    "#plot_chords(wiki_params, wiki_chordtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wiki_inits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "dcml-harmony-and-ornamentation",
   "language": "python",
   "name": "dcml-harmony-and-ornamentation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
